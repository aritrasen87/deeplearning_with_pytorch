{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5311346",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-05T09:16:04.664127Z",
     "iopub.status.busy": "2022-03-05T09:16:04.663006Z",
     "iopub.status.idle": "2022-03-05T09:16:17.407964Z",
     "shell.execute_reply": "2022-03-05T09:16:17.40683Z",
     "shell.execute_reply.started": "2022-03-05T09:16:04.663958Z"
    },
    "papermill": {
     "duration": 0.047707,
     "end_time": "2023-11-10T05:12:27.391227",
     "exception": false,
     "start_time": "2023-11-10T05:12:27.343520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is part of the below youtube Deep Learning with Pytorch : From Zero to GNN Series.\n",
    "\n",
    "Deep Learning with Pytorch Youtube series: https://www.youtube.com/playlist?list=PLOrU905yPYXJsJSHJsiE779KfcrRCgz4v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ededcc79",
   "metadata": {
    "papermill": {
     "duration": 0.045478,
     "end_time": "2023-11-10T05:12:27.485109",
     "exception": false,
     "start_time": "2023-11-10T05:12:27.439631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9caaa9f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:27.587536Z",
     "iopub.status.busy": "2023-11-10T05:12:27.586789Z",
     "iopub.status.idle": "2023-11-10T05:12:29.112167Z",
     "shell.execute_reply": "2023-11-10T05:12:29.111417Z",
     "shell.execute_reply.started": "2023-11-10T04:01:24.487942Z"
    },
    "papermill": {
     "duration": 1.581229,
     "end_time": "2023-11-10T05:12:29.112343",
     "exception": false,
     "start_time": "2023-11-10T05:12:27.531114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os , string\n",
    "# we will be using pytorch to build the model , hence importing required torch essentials\n",
    "import torch\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b654f",
   "metadata": {
    "papermill": {
     "duration": 0.045795,
     "end_time": "2023-11-10T05:12:29.204429",
     "exception": false,
     "start_time": "2023-11-10T05:12:29.158634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset Details:\n",
    "\n",
    "Dataset contains English sentences and corresponding Korean sentences. \n",
    "\n",
    "Our Machine translation model will take the english sentence and will translate the same to Koren sentence. \n",
    "\n",
    "We have train/test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff0dd28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:29.302939Z",
     "iopub.status.busy": "2023-11-10T05:12:29.302049Z",
     "iopub.status.idle": "2023-11-10T05:12:29.304213Z",
     "shell.execute_reply": "2023-11-10T05:12:29.304716Z",
     "shell.execute_reply.started": "2023-11-10T04:04:20.964274Z"
    },
    "papermill": {
     "duration": 0.054644,
     "end_time": "2023-11-10T05:12:29.304863",
     "exception": false,
     "start_time": "2023-11-10T05:12:29.250219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file paths\n",
    "eng_train = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_train_en-ko.raw.en'\n",
    "ko_train = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_train_en-ko.raw.ko'\n",
    "\n",
    "eng_test = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_test1_en-ko.raw.en'\n",
    "ko_test = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_test1_en-ko.raw.ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96783d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:29.401584Z",
     "iopub.status.busy": "2023-11-10T05:12:29.400963Z",
     "iopub.status.idle": "2023-11-10T05:12:29.403159Z",
     "shell.execute_reply": "2023-11-10T05:12:29.403604Z",
     "shell.execute_reply.started": "2023-11-10T04:04:29.625625Z"
    },
    "papermill": {
     "duration": 0.052353,
     "end_time": "2023-11-10T05:12:29.403742",
     "exception": false,
     "start_time": "2023-11-10T05:12:29.351389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.readlines()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04723aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:29.500232Z",
     "iopub.status.busy": "2023-11-10T05:12:29.499633Z",
     "iopub.status.idle": "2023-11-10T05:12:30.270702Z",
     "shell.execute_reply": "2023-11-10T05:12:30.270113Z",
     "shell.execute_reply.started": "2023-11-10T04:04:34.687599Z"
    },
    "papermill": {
     "duration": 0.820777,
     "end_time": "2023-11-10T05:12:30.270835",
     "exception": false,
     "start_time": "2023-11-10T05:12:29.450058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the files\n",
    "df_eng_train = read_text(eng_train)\n",
    "df_ko_train = read_text(ko_train)\n",
    "\n",
    "df_eng_test = read_text(eng_test)\n",
    "df_ko_test = read_text(ko_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3cb35f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:30.372133Z",
     "iopub.status.busy": "2023-11-10T05:12:30.371386Z",
     "iopub.status.idle": "2023-11-10T05:12:30.375004Z",
     "shell.execute_reply": "2023-11-10T05:12:30.375517Z",
     "shell.execute_reply.started": "2023-11-10T04:04:42.424734Z"
    },
    "papermill": {
     "duration": 0.057663,
     "end_time": "2023-11-10T05:12:30.375653",
     "exception": false,
     "start_time": "2023-11-10T05:12:30.317990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166215, 166215, 1982, 1982)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the length of the different datasets\n",
    "\n",
    "len(df_eng_train) , len(df_ko_train) , len(df_eng_test) , len(df_ko_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99f931",
   "metadata": {
    "papermill": {
     "duration": 0.04554,
     "end_time": "2023-11-10T05:12:30.467722",
     "exception": false,
     "start_time": "2023-11-10T05:12:30.422182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "1. Remove punctuation\n",
    "2. To lower case\n",
    "3. Remove new line charecters\n",
    "4. Split into indivisual words\n",
    "5. Build vocabulary of English and Korean Language \n",
    "     - index2word\n",
    "     - word2index\n",
    "6. Encoding and Padding each sentences from both language\n",
    "7. Prepare train/test batches of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3df55224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:30.593630Z",
     "iopub.status.busy": "2023-11-10T05:12:30.577614Z",
     "iopub.status.idle": "2023-11-10T05:12:32.623204Z",
     "shell.execute_reply": "2023-11-10T05:12:32.622600Z",
     "shell.execute_reply.started": "2023-11-10T04:07:15.679858Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 2.109417,
     "end_time": "2023-11-10T05:12:32.623361",
     "exception": false,
     "start_time": "2023-11-10T05:12:30.513944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "df_eng_train = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_eng_train]\n",
    "df_ko_train = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_ko_train]\n",
    "df_eng_test = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_eng_test]\n",
    "df_ko_test = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_ko_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd2ad3aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:32.727977Z",
     "iopub.status.busy": "2023-11-10T05:12:32.727185Z",
     "iopub.status.idle": "2023-11-10T05:12:32.730206Z",
     "shell.execute_reply": "2023-11-10T05:12:32.730673Z",
     "shell.execute_reply.started": "2023-11-10T04:07:18.680778Z"
    },
    "papermill": {
     "duration": 0.057991,
     "end_time": "2023-11-10T05:12:32.730824",
     "exception": false,
     "start_time": "2023-11-10T05:12:32.672833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And were going to tell you some stories from the sea here in video \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at one of the sentence\n",
    "df_eng_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba26ab39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:32.830613Z",
     "iopub.status.busy": "2023-11-10T05:12:32.829985Z",
     "iopub.status.idle": "2023-11-10T05:12:32.833844Z",
     "shell.execute_reply": "2023-11-10T05:12:32.833349Z",
     "shell.execute_reply.started": "2023-11-10T04:07:29.592160Z"
    },
    "papermill": {
     "duration": 0.055329,
     "end_time": "2023-11-10T05:12:32.833960",
     "exception": false,
     "start_time": "2023-11-10T05:12:32.778631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Applause David Gallo This is Bill Lange Im Dave Gallo \n",
      " Koren: 박수 이쪽은 Bill Lange 이고 저는 David Gallo입니다 \n",
      "\n",
      "English: And were going to tell you some stories from the sea here in video \n",
      " Koren: 우리는 여러분에게 바닷속 이야기를 영상과 함께 들려주고자 합니다 \n",
      "\n",
      "English: Weve got some of the most incredible video of Titanic thats ever been seen and were not going to show you any of it \n",
      " Koren: 저희는 끝내주는 타이타닉 비디오도 있긴 합니다만 뭐여기서는 눈꼽만큼도 보여줄 생각이없습니다 \n",
      "\n",
      "English: Laughter The truth of the matter is that the Titanic  even though its breaking all sorts of box office records  its not the most exciting story from the sea \n",
      " Koren: 웃음 비록 타이타닉이 박스오피스에서 굉장한 실적을 거두긴 했지만 바다가 들려주는 이야기 중 가장 재밌는 것은 아닙니다 \n",
      "\n",
      "English: And the problem I think is that we take the ocean for granted \n",
      " Koren: 문제라면 우리는 우리가 바다를 이미 알고있다고 믿는거죠 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking into 5 pair of sentence from both the languages\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"English: {} \\n Koren: {} \\n\".format(df_eng_train[i].strip(), df_ko_train[i].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f62914df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:33.000717Z",
     "iopub.status.busy": "2023-11-10T05:12:32.967721Z",
     "iopub.status.idle": "2023-11-10T05:12:34.369102Z",
     "shell.execute_reply": "2023-11-10T05:12:34.368375Z",
     "shell.execute_reply.started": "2023-11-10T04:07:36.989408Z"
    },
    "papermill": {
     "duration": 1.488084,
     "end_time": "2023-11-10T05:12:34.369246",
     "exception": false,
     "start_time": "2023-11-10T05:12:32.881162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to lower the words and remove new lines charecters\n",
    "for i in range(len(df_eng_train)):\n",
    "    df_eng_train[i] = df_eng_train[i].lower().rstrip(\"\\n\").split()\n",
    "    df_ko_train[i] = df_ko_train[i].lower().rstrip(\"\\n\").split()\n",
    "    \n",
    "for i in range(len(df_eng_test)):\n",
    "    df_eng_test[i] = df_eng_test[i].lower().rstrip(\"\\n\").split()\n",
    "    df_ko_test[i] = df_ko_test[i].lower().rstrip(\"\\n\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7a387e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:34.474450Z",
     "iopub.status.busy": "2023-11-10T05:12:34.473699Z",
     "iopub.status.idle": "2023-11-10T05:12:34.477233Z",
     "shell.execute_reply": "2023-11-10T05:12:34.476621Z",
     "shell.execute_reply.started": "2023-11-10T04:07:44.514895Z"
    },
    "papermill": {
     "duration": 0.056039,
     "end_time": "2023-11-10T05:12:34.477361",
     "exception": false,
     "start_time": "2023-11-10T05:12:34.421322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'were',\n",
       " 'going',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'some',\n",
       " 'stories',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'here',\n",
       " 'in',\n",
       " 'video']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at one of the sentence after the inital preprocess\n",
    "df_eng_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fccae3d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:12:34.607760Z",
     "iopub.status.busy": "2023-11-10T05:12:34.607104Z",
     "iopub.status.idle": "2023-11-10T05:53:31.468945Z",
     "shell.execute_reply": "2023-11-10T05:53:31.469496Z",
     "shell.execute_reply.started": "2023-11-10T04:31:52.229724Z"
    },
    "papermill": {
     "duration": 2456.943645,
     "end_time": "2023-11-10T05:53:31.469674",
     "exception": false,
     "start_time": "2023-11-10T05:12:34.526029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English index to word done\n",
      "Koren index to word done\n"
     ]
    }
   ],
   "source": [
    "# bulding the vocabulary for English and Korean Language\n",
    "# first we will build the index 2 word mapping\n",
    "\n",
    "\n",
    "en_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"] # <PAD> will be the zero'th index\n",
    "ko_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "\n",
    "for ds in [df_eng_train , df_eng_test]:\n",
    "    for sentence in ds:\n",
    "        for token in sentence:\n",
    "            if token not in en_index2word:\n",
    "                en_index2word.append(token)\n",
    "\n",
    "print('English index to word done')                \n",
    "                \n",
    "for ds in [df_ko_train , df_ko_test]:\n",
    "    for sentence in ds:\n",
    "        for token in sentence:\n",
    "            if token not in ko_index2word:\n",
    "                ko_index2word.append(token)\n",
    "\n",
    "print('Koren index to word done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e0952d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:31.585238Z",
     "iopub.status.busy": "2023-11-10T05:53:31.572287Z",
     "iopub.status.idle": "2023-11-10T05:53:31.704882Z",
     "shell.execute_reply": "2023-11-10T05:53:31.705375Z"
    },
    "papermill": {
     "duration": 0.187513,
     "end_time": "2023-11-10T05:53:31.705554",
     "exception": false,
     "start_time": "2023-11-10T05:53:31.518041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # dumping into pickle files for future use\n",
    "from pickle import dump\n",
    "\n",
    "dump(en_index2word, open('en_index2word.pkl', 'wb'))\n",
    "dump(ko_index2word, open('ko_index2word.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "732ac52a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:31.822144Z",
     "iopub.status.busy": "2023-11-10T05:53:31.816927Z",
     "iopub.status.idle": "2023-11-10T05:53:31.935821Z",
     "shell.execute_reply": "2023-11-10T05:53:31.935232Z",
     "shell.execute_reply.started": "2023-11-10T04:32:03.386034Z"
    },
    "papermill": {
     "duration": 0.177134,
     "end_time": "2023-11-10T05:53:31.935954",
     "exception": false,
     "start_time": "2023-11-10T05:53:31.758820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "#en_index2word = load(open('../input/nlpasgn/en_index2word.pkl', 'rb'))\n",
    "#ko_index2word = load(open('../input/nlpasgn/ko_index2word.pkl', 'rb'))\n",
    "\n",
    "# building the reverse word2index mapping using index2word dictionaries\n",
    "\n",
    "en_word2idx = {token : idx for idx , token in enumerate(en_index2word)}\n",
    "ko_word2idx = {token : idx for idx , token in enumerate(ko_index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c40d00ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:32.037520Z",
     "iopub.status.busy": "2023-11-10T05:53:32.036720Z",
     "iopub.status.idle": "2023-11-10T05:53:32.039311Z",
     "shell.execute_reply": "2023-11-10T05:53:32.038805Z",
     "shell.execute_reply.started": "2023-11-10T04:32:10.090511Z"
    },
    "papermill": {
     "duration": 0.054621,
     "end_time": "2023-11-10T05:53:32.039426",
     "exception": false,
     "start_time": "2023-11-10T05:53:31.984805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looking the dictionaries and the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00ad8661",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:32.143531Z",
     "iopub.status.busy": "2023-11-10T05:53:32.142736Z",
     "iopub.status.idle": "2023-11-10T05:53:32.145510Z",
     "shell.execute_reply": "2023-11-10T05:53:32.145997Z",
     "shell.execute_reply.started": "2023-11-10T04:32:13.201423Z"
    },
    "papermill": {
     "duration": 0.057717,
     "end_time": "2023-11-10T05:53:32.146161",
     "exception": false,
     "start_time": "2023-11-10T05:53:32.088444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('이고', 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_index2word[7] , ko_word2idx['이고']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "234bc209",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:32.248815Z",
     "iopub.status.busy": "2023-11-10T05:53:32.248064Z",
     "iopub.status.idle": "2023-11-10T05:53:32.250838Z",
     "shell.execute_reply": "2023-11-10T05:53:32.251346Z",
     "shell.execute_reply.started": "2023-11-10T04:32:19.657337Z"
    },
    "papermill": {
     "duration": 0.055806,
     "end_time": "2023-11-10T05:53:32.251475",
     "exception": false,
     "start_time": "2023-11-10T05:53:32.195669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gallo', 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_index2word[5] , en_word2idx['gallo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "321648e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:32.429738Z",
     "iopub.status.busy": "2023-11-10T05:53:32.397293Z",
     "iopub.status.idle": "2023-11-10T05:53:32.433795Z",
     "shell.execute_reply": "2023-11-10T05:53:32.433176Z",
     "shell.execute_reply.started": "2023-11-10T04:32:43.808628Z"
    },
    "papermill": {
     "duration": 0.133555,
     "end_time": "2023-11-10T05:53:32.433920",
     "exception": false,
     "start_time": "2023-11-10T05:53:32.300365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English : 17.39973528261589\n",
      "Korean : 12.162939566224468\n"
     ]
    }
   ],
   "source": [
    "# Average sentence length in Training dataset for both the languages\n",
    "\n",
    "print('English :',sum([len(sent) for sent in df_eng_train])/len(df_eng_train))\n",
    "\n",
    "print('Korean :',sum([len(sent) for sent in df_ko_train])/len(df_ko_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f833f6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:32.536884Z",
     "iopub.status.busy": "2023-11-10T05:53:32.536315Z",
     "iopub.status.idle": "2023-11-10T05:53:32.539093Z",
     "shell.execute_reply": "2023-11-10T05:53:32.538593Z",
     "shell.execute_reply.started": "2023-11-10T04:33:00.281964Z"
    },
    "papermill": {
     "duration": 0.055455,
     "end_time": "2023-11-10T05:53:32.539207",
     "exception": false,
     "start_time": "2023-11-10T05:53:32.483752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looking the average sentence lengths we are setting the seq length to max 25\n",
    "seq_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "242a8cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:32.646563Z",
     "iopub.status.busy": "2023-11-10T05:53:32.645981Z",
     "iopub.status.idle": "2023-11-10T05:53:32.648939Z",
     "shell.execute_reply": "2023-11-10T05:53:32.648352Z",
     "shell.execute_reply.started": "2023-11-10T04:41:42.432645Z"
    },
    "papermill": {
     "duration": 0.059228,
     "end_time": "2023-11-10T05:53:32.649071",
     "exception": false,
     "start_time": "2023-11-10T05:53:32.589843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will do encoding(using word2index mapping) and padding for each sentence to the max seq_length\n",
    "\n",
    "def encoding_padding(vocab , sentence , max_sent_length):\n",
    "    \n",
    "    SOS = [vocab[\"<SOS>\"]] # we will add start of sentence and end of sentence token at each sentence\n",
    "    EOS = [vocab[\"<EOS>\"]]\n",
    "    PAD = [vocab[\"<PAD>\"]]\n",
    "    \n",
    "    if len(sentence) < (max_sent_length - 2): # -2 is for SOS and EOS\n",
    "        pads = ((max_sent_length - 2) - len(sentence)) * PAD\n",
    "        encoding = [vocab[word] for word in sentence]\n",
    "        return SOS + encoding + EOS + pads\n",
    "    else:\n",
    "        encoding = [vocab[word] for word in sentence[:(max_sent_length - 2)]]\n",
    "        return SOS + encoding + EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f07c9",
   "metadata": {
    "papermill": {
     "duration": 0.04946,
     "end_time": "2023-11-10T05:53:32.748558",
     "exception": false,
     "start_time": "2023-11-10T05:53:32.699098",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Preparing training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdb23ea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:32.865575Z",
     "iopub.status.busy": "2023-11-10T05:53:32.855139Z",
     "iopub.status.idle": "2023-11-10T05:53:36.525869Z",
     "shell.execute_reply": "2023-11-10T05:53:36.525290Z",
     "shell.execute_reply.started": "2023-11-10T04:41:57.145833Z"
    },
    "papermill": {
     "duration": 3.727748,
     "end_time": "2023-11-10T05:53:36.526002",
     "exception": false,
     "start_time": "2023-11-10T05:53:32.798254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoding every sentence in train and test\n",
    "encoded_train_en = [encoding_padding(en_word2idx,sent,seq_length) for sent in df_eng_train]\n",
    "encoded_train_ko = [encoding_padding(ko_word2idx,sent,seq_length) for sent in df_ko_train]\n",
    "encoded_test_en = [encoding_padding(en_word2idx,sent,seq_length) for sent in df_eng_test]\n",
    "encoded_test_ko = [encoding_padding(ko_word2idx,sent,seq_length) for sent in df_ko_test]\n",
    "\n",
    "# creating numpy array for train and test\n",
    "train_x = np.array(encoded_train_en)\n",
    "train_y = np.array(encoded_train_ko)\n",
    "\n",
    "test_x = np.array(encoded_test_en)\n",
    "test_y = np.array(encoded_test_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "995f8ebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:36.660955Z",
     "iopub.status.busy": "2023-11-10T05:53:36.633801Z",
     "iopub.status.idle": "2023-11-10T05:53:36.741186Z",
     "shell.execute_reply": "2023-11-10T05:53:36.740528Z"
    },
    "papermill": {
     "duration": 0.162414,
     "end_time": "2023-11-10T05:53:36.741336",
     "exception": false,
     "start_time": "2023-11-10T05:53:36.578922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#creating pickles for future use\n",
    "\n",
    "dump(train_x, open('train_x.pkl', 'wb'))\n",
    "dump(train_y, open('train_y.pkl', 'wb'))\n",
    "dump(test_x, open('test_x.pkl', 'wb'))\n",
    "dump(test_y, open('test_y.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46fee8a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:36.848269Z",
     "iopub.status.busy": "2023-11-10T05:53:36.847328Z",
     "iopub.status.idle": "2023-11-10T05:53:36.849827Z",
     "shell.execute_reply": "2023-11-10T05:53:36.849370Z",
     "shell.execute_reply.started": "2022-03-08T07:05:43.253477Z"
    },
    "papermill": {
     "duration": 0.056063,
     "end_time": "2023-11-10T05:53:36.849942",
     "exception": false,
     "start_time": "2023-11-10T05:53:36.793879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the train test numpy array from pickles \n",
    "# train_x = load(open('../input/nlpasgn/train_x.pkl', 'rb'))\n",
    "# train_y = load(open('../input/nlpasgn/train_y.pkl', 'rb'))\n",
    "# test_x = load(open('../input/nlpasgn/test_x.pkl', 'rb'))\n",
    "# test_y = load(open('../input/nlpasgn/test_y.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b8200e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:37.030272Z",
     "iopub.status.busy": "2023-11-10T05:53:37.029596Z",
     "iopub.status.idle": "2023-11-10T05:53:37.032736Z",
     "shell.execute_reply": "2023-11-10T05:53:37.033182Z",
     "shell.execute_reply.started": "2023-11-10T04:42:10.701149Z"
    },
    "papermill": {
     "duration": 0.131304,
     "end_time": "2023-11-10T05:53:37.033327",
     "exception": false,
     "start_time": "2023-11-10T05:53:36.902023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the GPU availability and setting the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f9746a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:37.142967Z",
     "iopub.status.busy": "2023-11-10T05:53:37.142391Z",
     "iopub.status.idle": "2023-11-10T05:53:37.145048Z",
     "shell.execute_reply": "2023-11-10T05:53:37.144583Z",
     "shell.execute_reply.started": "2023-11-10T04:44:10.997088Z"
    },
    "papermill": {
     "duration": 0.061463,
     "end_time": "2023-11-10T05:53:37.145167",
     "exception": false,
     "start_time": "2023-11-10T05:53:37.083704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the Torch tensor dataloaders\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x) , torch.from_numpy(train_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x) , torch.from_numpy(test_y))\n",
    "\n",
    "batch_size = 30\n",
    "\n",
    "train_dl = DataLoader(train_data,shuffle=True,batch_size=batch_size,drop_last=True)\n",
    "test_dl = DataLoader(test_data,shuffle=True,batch_size=batch_size,drop_last=True)\n",
    "\n",
    "# The drop_last=True parameter ignores the last batch (when the number of examples in your dataset \n",
    "# is not divisible by your batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ab9022",
   "metadata": {
    "papermill": {
     "duration": 0.050275,
     "end_time": "2023-11-10T05:53:37.246231",
     "exception": false,
     "start_time": "2023-11-10T05:53:37.195956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building the neural Network\n",
    "We will create the Encoder and Decoder networks , inside them we will use GRU reccurent network which generally performs better than vanila RNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f3e682a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:37.355394Z",
     "iopub.status.busy": "2023-11-10T05:53:37.354709Z",
     "iopub.status.idle": "2023-11-10T05:53:37.357259Z",
     "shell.execute_reply": "2023-11-10T05:53:37.356769Z",
     "shell.execute_reply.started": "2023-11-10T04:51:26.076900Z"
    },
    "papermill": {
     "duration": 0.060473,
     "end_time": "2023-11-10T05:53:37.357379",
     "exception": false,
     "start_time": "2023-11-10T05:53:37.296906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0) # as we specified padding as zero\n",
    "        \n",
    "        # RNN layer. The input and output are both of the same size \n",
    "        #  since embedding size = hidden size in this example\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # The inputs are first transformed into embeddings\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "\n",
    "        # As in any RNN, the new input and the previous hidden states are fed\n",
    "        #  into the model at each time step \n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # This method is used to create the innitial hidden states for the encoder\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2417b3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:37.466712Z",
     "iopub.status.busy": "2023-11-10T05:53:37.466071Z",
     "iopub.status.idle": "2023-11-10T05:53:37.468680Z",
     "shell.execute_reply": "2023-11-10T05:53:37.468229Z",
     "shell.execute_reply.started": "2023-11-10T04:51:32.102998Z"
    },
    "papermill": {
     "duration": 0.060726,
     "end_time": "2023-11-10T05:53:37.468796",
     "exception": false,
     "start_time": "2023-11-10T05:53:37.408070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=0)\n",
    "        \n",
    "        # The RNN layer\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size)\n",
    "\n",
    "        # Fully-connected layer for scores\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "        # Applying Softmax to the scores\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # Feeding input through embedding layer\n",
    "        output = self.embedding(input)\n",
    "\n",
    "        # Applying an activation function (ReLu)\n",
    "        output = F.relu(output)\n",
    "\n",
    "        # Feeding input and previous hidden state\n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "\n",
    "        # Outputting scores from the final time-step\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "    # We do not need an .initHidden() method for the decoder since the \n",
    "    #  encoder output will act as input in the first decoder time-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ffd0071",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:37.576995Z",
     "iopub.status.busy": "2023-11-10T05:53:37.576260Z",
     "iopub.status.idle": "2023-11-10T05:53:43.100773Z",
     "shell.execute_reply": "2023-11-10T05:53:43.100211Z",
     "shell.execute_reply.started": "2023-11-10T04:52:31.653633Z"
    },
    "papermill": {
     "duration": 5.581397,
     "end_time": "2023-11-10T05:53:43.100937",
     "exception": false,
     "start_time": "2023-11-10T05:53:37.519540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initializing the networks\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderRNN(len(en_index2word), hidden_size).to(device)\n",
    "decoder = DecoderRNN(hidden_size, len(ko_index2word)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffd3e76f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:43.210681Z",
     "iopub.status.busy": "2023-11-10T05:53:43.210064Z",
     "iopub.status.idle": "2023-11-10T05:53:43.213243Z",
     "shell.execute_reply": "2023-11-10T05:53:43.213689Z",
     "shell.execute_reply.started": "2023-11-10T04:52:37.406326Z"
    },
    "papermill": {
     "duration": 0.060867,
     "end_time": "2023-11-10T05:53:43.213832",
     "exception": false,
     "start_time": "2023-11-10T05:53:43.152965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(53838, 256, padding_idx=0)\n",
      "  (rnn): RNN(256, 256, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# looking at the networks\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f4ca78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:43.320600Z",
     "iopub.status.busy": "2023-11-10T05:53:43.319910Z",
     "iopub.status.idle": "2023-11-10T05:53:43.322682Z",
     "shell.execute_reply": "2023-11-10T05:53:43.323179Z",
     "shell.execute_reply.started": "2023-11-10T04:52:45.050299Z"
    },
    "papermill": {
     "duration": 0.058525,
     "end_time": "2023-11-10T05:53:43.323324",
     "exception": false,
     "start_time": "2023-11-10T05:53:43.264799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecoderRNN(\n",
      "  (embedding): Embedding(295179, 256, padding_idx=0)\n",
      "  (rnn): RNN(256, 256)\n",
      "  (out): Linear(in_features=256, out_features=295179, bias=True)\n",
      "  (softmax): LogSoftmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4cab2ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:43.431571Z",
     "iopub.status.busy": "2023-11-10T05:53:43.430872Z",
     "iopub.status.idle": "2023-11-10T05:53:43.433416Z",
     "shell.execute_reply": "2023-11-10T05:53:43.432930Z",
     "shell.execute_reply.started": "2023-11-10T04:52:54.913067Z"
    },
    "papermill": {
     "duration": 0.05875,
     "end_time": "2023-11-10T05:53:43.433534",
     "exception": false,
     "start_time": "2023-11-10T05:53:43.374784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # loss function\n",
    "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = 3e-3) #encoder optimizer with models params and Learning rate\n",
    "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = 3e-3) #decoder optimizer with models params and Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f291d489",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:43.540880Z",
     "iopub.status.busy": "2023-11-10T05:53:43.540086Z",
     "iopub.status.idle": "2023-11-10T05:53:43.542150Z",
     "shell.execute_reply": "2023-11-10T05:53:43.542600Z",
     "shell.execute_reply.started": "2023-11-10T04:54:33.964718Z"
    },
    "papermill": {
     "duration": 0.057864,
     "end_time": "2023-11-10T05:53:43.542740",
     "exception": false,
     "start_time": "2023-11-10T05:53:43.484876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_length = target_length = seq_length # setting the sizes\n",
    "\n",
    "losses = []\n",
    "\n",
    "SOS = en_word2idx[\"<SOS>\"]\n",
    "EOS = en_word2idx[\"<EOS>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b392f7",
   "metadata": {
    "papermill": {
     "duration": 0.051059,
     "end_time": "2023-11-10T05:53:43.646229",
     "exception": false,
     "start_time": "2023-11-10T05:53:43.595170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Model Traning for Encoder and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3c5b0b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T05:53:43.763719Z",
     "iopub.status.busy": "2023-11-10T05:53:43.763053Z",
     "iopub.status.idle": "2023-11-10T12:33:42.203868Z",
     "shell.execute_reply": "2023-11-10T12:33:42.203308Z",
     "shell.execute_reply.started": "2023-11-10T05:05:50.393510Z"
    },
    "papermill": {
     "duration": 23998.505981,
     "end_time": "2023-11-10T12:33:42.204045",
     "exception": false,
     "start_time": "2023-11-10T05:53:43.698064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "0 12.60581111907959\n",
      "100 6.676273879438344\n",
      "200 6.434750955496261\n",
      "300 6.340621338334194\n",
      "400 6.273398552749519\n",
      "500 6.251806241071629\n",
      "600 6.217007022134079\n",
      "700 6.196158064244988\n",
      "800 6.177280149805115\n",
      "900 6.156230653959692\n",
      "1000 6.155052890548935\n",
      "1100 6.14193633813191\n",
      "1200 6.128854859977042\n",
      "1300 6.113608765290573\n",
      "1400 6.100915994923256\n",
      "1500 6.0986096749378795\n",
      "1600 6.0909373335805554\n",
      "1700 6.088252798379834\n",
      "1800 6.089600816691736\n",
      "1900 6.08392581959764\n",
      "2000 6.08106612611091\n",
      "2100 6.076930586012813\n",
      "2200 6.074076438264271\n",
      "2300 6.072767279656852\n",
      "2400 6.0701261766251795\n",
      "2500 6.066780853919724\n",
      "2600 6.060044790038417\n",
      "2700 6.0556952202156795\n",
      "2800 6.055810739210102\n",
      "2900 6.05882224490913\n",
      "3000 6.060084414458283\n",
      "3100 6.057554266830292\n",
      "3200 6.054051150608271\n",
      "3300 6.0556468524487945\n",
      "3400 6.057505651489141\n",
      "3500 6.059530940542082\n",
      "3600 6.060405069640927\n",
      "3700 6.06171526363881\n",
      "3800 6.062188472662497\n",
      "3900 6.061791865772481\n",
      "4000 6.059570573860632\n",
      "4100 6.0596434971786834\n",
      "4200 6.062179381210047\n",
      "4300 6.062150665394957\n",
      "4400 6.062905868382054\n",
      "4500 6.061835574404554\n",
      "4600 6.064031907719805\n",
      "4700 6.06573249400613\n",
      "4800 6.070105201575786\n",
      "4900 6.071215403564024\n",
      "5000 6.0743197104712054\n",
      "5100 6.075165263906785\n",
      "5200 6.078197940957704\n",
      "5300 6.079247837358096\n",
      "5400 6.0819362569927975\n",
      "5500 6.084170430774061\n",
      "Epoch: 1\n",
      "0 6.085186206354301\n",
      "100 6.085054452950556\n",
      "200 6.083843347565718\n",
      "300 6.081800749236193\n",
      "400 6.081451660092682\n",
      "500 6.080247095139922\n",
      "600 6.07947919415721\n",
      "700 6.079490112658591\n",
      "800 6.077351554563192\n",
      "900 6.076925881881371\n",
      "1000 6.076550883267053\n",
      "1100 6.075445456562981\n",
      "1200 6.076230294165776\n",
      "1300 6.0748811435183665\n",
      "1400 6.073516803316073\n",
      "1500 6.0728494349976625\n",
      "1600 6.072952187039608\n",
      "1700 6.072605986503619\n",
      "1800 6.072328130355438\n",
      "1900 6.0719928471668165\n",
      "2000 6.069818111554237\n",
      "2100 6.069271644923781\n",
      "2200 6.070340024610312\n",
      "2300 6.069826788720451\n",
      "2400 6.071529521673126\n",
      "2500 6.070911226366278\n",
      "2600 6.07049488520508\n",
      "2700 6.069861724732238\n",
      "2800 6.0699389023455534\n",
      "2900 6.0700110536717\n",
      "3000 6.070491653989955\n",
      "3100 6.070934819617822\n",
      "3200 6.071575936811792\n",
      "3300 6.07426493325097\n",
      "3400 6.075362065296794\n",
      "3500 6.07769539936126\n",
      "3600 6.080431089452366\n",
      "3700 6.082697431035739\n",
      "3800 6.083229220381846\n",
      "3900 6.084093560153253\n",
      "4000 6.085727490590136\n",
      "4100 6.087734848665828\n",
      "4200 6.0889616694958\n",
      "4300 6.089573979704812\n",
      "4400 6.09269492893125\n",
      "4500 6.094305316310351\n",
      "4600 6.097741200366489\n",
      "4700 6.099987193553572\n",
      "4800 6.103264092407654\n",
      "4900 6.104827343327209\n",
      "5000 6.105917007553771\n",
      "5100 6.108801431577912\n",
      "5200 6.109955759024489\n",
      "5300 6.110219631805575\n",
      "5400 6.112501250837874\n",
      "5500 6.114718665053972\n",
      "Epoch: 2\n",
      "0 6.115233057318327\n",
      "100 6.114901939281548\n",
      "200 6.113916334874684\n",
      "300 6.113992191913331\n",
      "400 6.114985636952094\n",
      "500 6.115956865066424\n",
      "600 6.116103564475397\n",
      "700 6.116129938526638\n",
      "800 6.116878731545149\n",
      "900 6.118294629277754\n",
      "1000 6.1178213719372\n",
      "1100 6.117552955106956\n",
      "1200 6.118528246578666\n",
      "1300 6.119076009655931\n",
      "1400 6.119676215785616\n",
      "1500 6.121175330049633\n",
      "1600 6.122013775353439\n",
      "1700 6.122223313766395\n",
      "1800 6.1227181627276375\n",
      "1900 6.123281270015332\n",
      "2000 6.124450586265166\n",
      "2100 6.124606414029725\n",
      "2200 6.124488691475438\n",
      "2300 6.125120107443929\n",
      "2400 6.124926987710192\n",
      "2500 6.12566139466123\n",
      "2600 6.127047020722774\n",
      "2700 6.127502036158678\n",
      "2800 6.128402592683936\n",
      "2900 6.128775800095548\n",
      "3000 6.128841034653732\n",
      "3100 6.128689212730477\n",
      "3200 6.128838689410213\n",
      "3300 6.128825634280678\n",
      "3400 6.1280753295252515\n",
      "3500 6.1286869234823245\n",
      "3600 6.129995013507817\n",
      "3700 6.131222080969858\n",
      "3800 6.132223669715678\n",
      "3900 6.134150283723844\n",
      "4000 6.135233709140431\n",
      "4100 6.136277975501157\n",
      "4200 6.136088597634865\n",
      "4300 6.136488940934197\n",
      "4400 6.137253420504325\n",
      "4500 6.138306232496707\n",
      "4600 6.139748146366567\n",
      "4700 6.1416710081922945\n",
      "4800 6.14321979714629\n",
      "4900 6.144603277176225\n",
      "5000 6.145749643633121\n",
      "5100 6.148015652117803\n",
      "5200 6.147513580076247\n",
      "5300 6.147383904356666\n",
      "5400 6.147236460122182\n",
      "5500 6.147638337918857\n",
      "Epoch: 3\n",
      "0 6.148130213208064\n",
      "100 6.147788865637119\n",
      "200 6.14884277079209\n",
      "300 6.148226230140696\n",
      "400 6.147879664678424\n",
      "500 6.147040416924073\n",
      "600 6.146718639134322\n",
      "700 6.1458185281924775\n",
      "800 6.145761660556214\n",
      "900 6.146082590502777\n",
      "1000 6.146037915732423\n",
      "1100 6.145651772869716\n",
      "1200 6.145308335015659\n",
      "1300 6.1448961075352315\n",
      "1400 6.144768800132713\n",
      "1500 6.145672001577386\n",
      "1600 6.146280889603749\n",
      "1700 6.146317765114252\n",
      "1800 6.14637478896302\n",
      "1900 6.1457790282895\n",
      "2000 6.145136504569939\n",
      "2100 6.145048393741402\n",
      "2200 6.144979125780365\n",
      "2300 6.1444752447058635\n",
      "2400 6.145343525139831\n",
      "2500 6.14674370710673\n",
      "2600 6.147890761952811\n",
      "2700 6.148158597696901\n",
      "2800 6.148124515147872\n",
      "2900 6.1485058484669315\n",
      "3000 6.14839790105686\n",
      "3100 6.148253894578818\n",
      "3200 6.14913148628848\n",
      "3300 6.14986202643941\n",
      "3400 6.150365132420018\n",
      "3500 6.150074597565307\n",
      "3600 6.150439104206879\n",
      "3700 6.151407952254919\n",
      "3800 6.152133316328462\n",
      "3900 6.15322985404428\n",
      "4000 6.153569220178522\n",
      "4100 6.153798766246858\n",
      "4200 6.153931767789026\n",
      "4300 6.1542831230081525\n",
      "4400 6.154138014617233\n",
      "4500 6.153635751082982\n",
      "4600 6.1535231203920775\n",
      "4700 6.15409888959972\n",
      "4800 6.154694247883545\n",
      "4900 6.1542652882218425\n",
      "5000 6.1551037187806985\n",
      "5100 6.154652048455797\n",
      "5200 6.154712568396451\n",
      "5300 6.154706840668275\n",
      "5400 6.155081526037079\n",
      "5500 6.155744352358374\n",
      "Epoch: 4\n",
      "0 6.155838114384425\n",
      "100 6.155512997095307\n",
      "200 6.15504216938847\n",
      "300 6.155282359923372\n",
      "400 6.15518286606399\n",
      "500 6.155170330370647\n",
      "600 6.155864199269693\n",
      "700 6.155171405131785\n",
      "800 6.154967066728821\n",
      "900 6.154029469576689\n",
      "1000 6.153711607921392\n",
      "1100 6.152836160982451\n",
      "1200 6.152135649107483\n",
      "1300 6.1511767075894195\n",
      "1400 6.150505207688025\n",
      "1500 6.149807380222265\n",
      "1600 6.1489669753367195\n",
      "1700 6.148491784795962\n",
      "1800 6.147638791212728\n",
      "1900 6.146647085746542\n",
      "2000 6.146124255030091\n",
      "2100 6.145222885326336\n",
      "2200 6.144577039031431\n",
      "2300 6.1442741044948495\n",
      "2400 6.144422795027913\n",
      "2500 6.143885881176376\n",
      "2600 6.144673456317037\n",
      "2700 6.1462040412244265\n",
      "2800 6.147384434717549\n",
      "2900 6.147636968878974\n",
      "3000 6.1480205656306115\n",
      "3100 6.14851614190726\n",
      "3200 6.150213873756313\n",
      "3300 6.150931269566021\n",
      "3400 6.151802843004403\n",
      "3500 6.152389950022164\n",
      "3600 6.153513861685398\n",
      "3700 6.1542442022594805\n",
      "3800 6.154207054499067\n",
      "3900 6.154438854293059\n",
      "4000 6.154668978989331\n",
      "4100 6.155360726426631\n",
      "4200 6.155169108528898\n",
      "4300 6.1553792888978265\n",
      "4400 6.155019697082549\n",
      "4500 6.154814291588789\n",
      "4600 6.154770939692508\n",
      "4700 6.154688749614784\n",
      "4800 6.1555612130669335\n",
      "4900 6.155617686228285\n",
      "5000 6.155484435897237\n",
      "5100 6.155937928559779\n",
      "5200 6.156890502759733\n",
      "5300 6.1576141421877635\n",
      "5400 6.157756352129637\n",
      "5500 6.158434151491259\n"
     ]
    }
   ],
   "source": [
    "epochs = 5 # training the model for 10 epochs due time limitaions on the Kaggle Kernels\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('Epoch:',epoch)\n",
    "    for idx, batch in enumerate(train_dl):\n",
    "\n",
    "        # Creating initial hidden states for the encoder\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        # Sending to device \n",
    "        encoder_hidden = encoder_hidden.to(device)\n",
    "\n",
    "        # Assigning the input and sending to device\n",
    "        input_tensor = batch[0].to(device)\n",
    "\n",
    "        # Assigning the output and sending to device\n",
    "        target_tensor = batch[1].to(device)\n",
    "        \n",
    "\n",
    "        # Clearing gradients\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "\n",
    "        # Enabling gradient calculation\n",
    "        with torch.set_grad_enabled(True):\n",
    "            \n",
    "            # Feeding batch into encoder\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "            # This is a placeholder tensor for decoder outputs. We send it to device as well\n",
    "            dec_result = torch.zeros(target_length, batch_size, len(ko_index2word)).to(device)\n",
    "\n",
    "            # Creating a batch of SOS tokens which will all be fed to the decoder\n",
    "            decoder_input = target_tensor[:, 0].unsqueeze(dim=0).to(device)\n",
    "\n",
    "            # Creating initial hidden states of the decoder by copying encoder hidden states\n",
    "            decoder_hidden = encoder_hidden\n",
    "\n",
    "            # For each time-step in decoding:\n",
    "            for i in range(1, target_length):\n",
    "                \n",
    "                # Feed input and previous hidden states \n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                \n",
    "                # Finding the best scoring word\n",
    "                best = decoder_output.argmax(1)\n",
    "\n",
    "                # Assigning next input as current best word\n",
    "                decoder_input = best.unsqueeze(dim=0) \n",
    "\n",
    "                # Creating an entry in the placeholder output tensor\n",
    "                dec_result[i] = decoder_output\n",
    "\n",
    "\n",
    "            # Creating scores and targets for loss calculation\n",
    "            scores = dec_result.transpose(1, 0)[1:].reshape(-1, dec_result.shape[2])\n",
    "            targets = target_tensor[1:].reshape(-1)\n",
    "\n",
    "            # Calculating loss\n",
    "            loss = criterion(scores, targets)\n",
    "            \n",
    "            # Performing backprop and clipping excess gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
    "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
    "\n",
    "            enc_optimizer.step() \n",
    "            dec_optimizer.step()\n",
    "\n",
    "            # Keeping track of loss\n",
    "            losses.append(loss.item())\n",
    "            # printing loss for every 100 iteration\n",
    "            if idx % 100 == 0:\n",
    "                print(idx, sum(losses)/len(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c16a6b8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T12:33:42.534214Z",
     "iopub.status.busy": "2023-11-10T12:33:42.533557Z",
     "iopub.status.idle": "2023-11-10T12:33:42.822781Z",
     "shell.execute_reply": "2023-11-10T12:33:42.823339Z"
    },
    "papermill": {
     "duration": 0.458248,
     "end_time": "2023-11-10T12:33:42.823524",
     "exception": false,
     "start_time": "2023-11-10T12:33:42.365276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f245ac3de10>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking the loss plot\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f35e3316",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T12:33:43.158240Z",
     "iopub.status.busy": "2023-11-10T12:33:43.157610Z",
     "iopub.status.idle": "2023-11-10T12:33:44.966974Z",
     "shell.execute_reply": "2023-11-10T12:33:44.966176Z",
     "shell.execute_reply.started": "2022-03-05T09:19:23.100395Z"
    },
    "papermill": {
     "duration": 1.979398,
     "end_time": "2023-11-10T12:33:44.967153",
     "exception": false,
     "start_time": "2023-11-10T12:33:42.987755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the models for future use\n",
    "\n",
    "encoder_path = \"encoder.pth\"\n",
    "torch.save(encoder, encoder_path)\n",
    "\n",
    "decoder_path = \"decoder.pth\"\n",
    "torch.save(decoder, decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbc6461f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T12:33:45.295931Z",
     "iopub.status.busy": "2023-11-10T12:33:45.295338Z",
     "iopub.status.idle": "2023-11-10T12:33:45.297931Z",
     "shell.execute_reply": "2023-11-10T12:33:45.297468Z",
     "shell.execute_reply.started": "2022-03-08T07:06:04.188093Z"
    },
    "papermill": {
     "duration": 0.168821,
     "end_time": "2023-11-10T12:33:45.298081",
     "exception": false,
     "start_time": "2023-11-10T12:33:45.129260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # load the models\n",
    "# encoder = torch.load('../input/nlpasgn/encoder.pth')\n",
    "# decoder = torch.load('../input/nlpasgn/dencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067c935",
   "metadata": {
    "papermill": {
     "duration": 0.163932,
     "end_time": "2023-11-10T12:33:45.622911",
     "exception": false,
     "start_time": "2023-11-10T12:33:45.458979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Making Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb3b838e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T12:33:45.980494Z",
     "iopub.status.busy": "2023-11-10T12:33:45.979848Z",
     "iopub.status.idle": "2023-11-10T12:33:45.981852Z",
     "shell.execute_reply": "2023-11-10T12:33:45.982292Z",
     "shell.execute_reply.started": "2022-03-08T07:06:09.737975Z"
    },
    "papermill": {
     "duration": 0.175247,
     "end_time": "2023-11-10T12:33:45.982447",
     "exception": false,
     "start_time": "2023-11-10T12:33:45.807200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "\n",
    "def make_predictions(test_sentence):\n",
    "    # Tokenizing, Encoding, transforming to Tensor\n",
    "    test_sentence = torch.tensor(encoding_padding(en_word2idx, test_sentence, seq_length)).unsqueeze(dim=0)\n",
    "    \n",
    "    encoder_hidden = torch.zeros(1, 1, hidden_size) # initial input to encoder\n",
    "    encoder_hidden = encoder_hidden.to(device) # taking to the tensor\n",
    "\n",
    "    input_tensor = test_sentence.to(device) # taking to the tensor\n",
    "\n",
    "    enc_optimizer.zero_grad()\n",
    "    dec_optimizer.zero_grad()\n",
    "\n",
    "    result = []\n",
    "\n",
    "    encoder_outputs = torch.zeros(seq_length, encoder.hidden_size, device=device)\n",
    "\n",
    "\n",
    "    with torch.set_grad_enabled(False): # turning of the gradients\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden) # passing the sentence through encoder\n",
    "\n",
    "        dec_result = torch.zeros(target_length, 1, len(ko_index2word)).to(device)\n",
    "\n",
    "        decoder_input = torch.tensor([SOS]).unsqueeze(dim=0).to(device) # sending the SOS to decoder\n",
    "        decoder_hidden = encoder_hidden\n",
    "        for di in range(1, target_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            best = decoder_output.argmax(1)\n",
    "            #print(best.to('cpu').item())\n",
    "            result.append(ko_index2word[best.to('cpu').item()])\n",
    "            if best.item() == EOS: # break when we reach EOS\n",
    "                break\n",
    "\n",
    "            decoder_input = best.unsqueeze(dim=0) \n",
    "            dec_result[di] = decoder_output\n",
    "    #return \" \".join(result[:-1]) # removing EOS from result\n",
    "    return result[:-1] # removing EOS from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aaedfefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T12:33:46.312254Z",
     "iopub.status.busy": "2023-11-10T12:33:46.311425Z",
     "iopub.status.idle": "2023-11-10T12:33:46.407806Z",
     "shell.execute_reply": "2023-11-10T12:33:46.407303Z",
     "shell.execute_reply.started": "2022-03-08T07:06:13.513502Z"
    },
    "papermill": {
     "duration": 0.263081,
     "end_time": "2023-11-10T12:33:46.407944",
     "exception": false,
     "start_time": "2023-11-10T12:33:46.144863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Number in test set: ---------- 0 ---------------\n",
      "\n",
      "Actual English Sentence :  allison hunt my three minutes hasnt started yet has it\n",
      "Translated Predictions: ['웃음', '비무장지대', '기독교']\n",
      "Actual Sentence: ['아직', '3분', '시작된', '건', '아니죠', '그렇죠']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 1 ---------------\n",
      "\n",
      "Actual English Sentence :  chris anderson no you cant start the three minutes\n",
      "Translated Predictions: ['홍콩', '유대인들뿐만', '<PAD>', '130']\n",
      "Actual Sentence: ['크리스', '앤더슨네', '맘대로', '시작하실', '수', '없습니다']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 2 ---------------\n",
      "\n",
      "Actual English Sentence :  reset the three minutes thats just not fair\n",
      "Translated Predictions: ['그리고', '제']\n",
      "Actual Sentence: ['3분', '다시', '설정해주세요', '이건', '반칙입니다']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 3 ---------------\n",
      "\n",
      "Actual English Sentence :  ah oh my god its harsh up here\n",
      "Translated Predictions: ['그리고', '제']\n",
      "Actual Sentence: ['앨리슨', '헌트', '어머나', '여기', '참', '냉정하네요']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 4 ---------------\n",
      "\n",
      "Actual English Sentence :  i mean im nervous enough as it is\n",
      "Translated Predictions: ['그리고', '제']\n",
      "Actual Sentence: ['정말이지', '긴장되네요']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Sentence Number in test set: ----------', i, '---------------\\n')\n",
    "    print('Actual English Sentence : ',\" \".join(df_eng_test[i]))\n",
    "    print('Translated Predictions:' , make_predictions(df_eng_test[i]))\n",
    "    print('Actual Sentence:' , df_ko_test[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baa908b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T12:33:46.738899Z",
     "iopub.status.busy": "2023-11-10T12:33:46.738181Z",
     "iopub.status.idle": "2023-11-10T12:33:46.830496Z",
     "shell.execute_reply": "2023-11-10T12:33:46.829968Z",
     "shell.execute_reply.started": "2022-03-08T07:19:39.122342Z"
    },
    "papermill": {
     "duration": 0.260305,
     "end_time": "2023-11-10T12:33:46.830621",
     "exception": false,
     "start_time": "2023-11-10T12:33:46.570316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# https://pytorch.org/text/stable/data_metrics.html\n",
    "\n",
    "def bleu(src_data, tar_data):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for i in zip(src_data , tar_data):\n",
    "        src = i[0]\n",
    "        trg = i[1]\n",
    "        prediction = make_predictions(src)\n",
    "        targets.append([str(ko_word2idx[word]) for word in trg])\n",
    "        outputs.append([str(ko_word2idx[word]) for word in prediction])\n",
    "    return bleu_score(outputs, targets,max_n=1,weights=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4fbe75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-10T12:33:47.184825Z",
     "iopub.status.busy": "2023-11-10T12:33:47.184224Z",
     "iopub.status.idle": "2023-11-10T12:34:18.321332Z",
     "shell.execute_reply": "2023-11-10T12:34:18.321826Z",
     "shell.execute_reply.started": "2022-03-08T07:19:40.645392Z"
    },
    "papermill": {
     "duration": 31.313383,
     "end_time": "2023-11-10T12:34:18.321983",
     "exception": false,
     "start_time": "2023-11-10T12:33:47.008600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score 11.16\n"
     ]
    }
   ],
   "source": [
    "# Bleu score on test dataset\n",
    "score = bleu(df_eng_test,df_ko_test)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26522.319042,
   "end_time": "2023-11-10T12:34:20.459744",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-10T05:12:18.140702",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
