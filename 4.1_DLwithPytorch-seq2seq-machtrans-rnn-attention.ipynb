{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413c3c40",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-05T09:16:04.664127Z",
     "iopub.status.busy": "2022-03-05T09:16:04.663006Z",
     "iopub.status.idle": "2022-03-05T09:16:17.407964Z",
     "shell.execute_reply": "2022-03-05T09:16:17.40683Z",
     "shell.execute_reply.started": "2022-03-05T09:16:04.663958Z"
    },
    "papermill": {
     "duration": 0.053391,
     "end_time": "2023-11-12T04:09:00.199561",
     "exception": false,
     "start_time": "2023-11-12T04:09:00.146170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is part of the below youtube Deep Learning with Pytorch : From Zero to GNN Series.\n",
    "\n",
    "Deep Learning with Pytorch Youtube series: https://www.youtube.com/playlist?list=PLOrU905yPYXJsJSHJsiE779KfcrRCgz4v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480b940",
   "metadata": {
    "papermill": {
     "duration": 0.04944,
     "end_time": "2023-11-12T04:09:00.297488",
     "exception": false,
     "start_time": "2023-11-12T04:09:00.248048",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc44e234",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:00.408947Z",
     "iopub.status.busy": "2023-11-12T04:09:00.405949Z",
     "iopub.status.idle": "2023-11-12T04:09:02.013711Z",
     "shell.execute_reply": "2023-11-12T04:09:02.012902Z",
     "shell.execute_reply.started": "2023-11-12T03:31:32.846496Z"
    },
    "papermill": {
     "duration": 1.665945,
     "end_time": "2023-11-12T04:09:02.013899",
     "exception": false,
     "start_time": "2023-11-12T04:09:00.347954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os , string\n",
    "# we will be using pytorch to build the model , hence importing required torch essentials\n",
    "import torch\n",
    "from torch.utils.data import DataLoader , TensorDataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ff1ef",
   "metadata": {
    "papermill": {
     "duration": 0.048605,
     "end_time": "2023-11-12T04:09:02.116547",
     "exception": false,
     "start_time": "2023-11-12T04:09:02.067942",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset Details:\n",
    "\n",
    "Dataset contains English sentences and corresponding Korean sentences. \n",
    "\n",
    "Our Machine translation model will take the english sentence and will translate the same to Koren sentence. \n",
    "\n",
    "We have train/test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99446958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:02.222004Z",
     "iopub.status.busy": "2023-11-12T04:09:02.221302Z",
     "iopub.status.idle": "2023-11-12T04:09:02.224003Z",
     "shell.execute_reply": "2023-11-12T04:09:02.223378Z",
     "shell.execute_reply.started": "2023-11-12T03:31:34.526525Z"
    },
    "papermill": {
     "duration": 0.058315,
     "end_time": "2023-11-12T04:09:02.224134",
     "exception": false,
     "start_time": "2023-11-12T04:09:02.165819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# file paths\n",
    "eng_train = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_train_en-ko.raw.en'\n",
    "ko_train = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_train_en-ko.raw.ko'\n",
    "\n",
    "eng_test = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_test1_en-ko.raw.en'\n",
    "ko_test = '/kaggle/input/englishkorean-multitarget-ted-talks-task-mttt/multitarget-ted/en-ko/raw/ted_test1_en-ko.raw.ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cfbbba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:02.327748Z",
     "iopub.status.busy": "2023-11-12T04:09:02.326846Z",
     "iopub.status.idle": "2023-11-12T04:09:02.329477Z",
     "shell.execute_reply": "2023-11-12T04:09:02.328947Z",
     "shell.execute_reply.started": "2023-11-12T03:31:34.532765Z"
    },
    "papermill": {
     "duration": 0.055699,
     "end_time": "2023-11-12T04:09:02.329609",
     "exception": false,
     "start_time": "2023-11-12T04:09:02.273910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.readlines()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1287b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:02.432226Z",
     "iopub.status.busy": "2023-11-12T04:09:02.430465Z",
     "iopub.status.idle": "2023-11-12T04:09:03.027002Z",
     "shell.execute_reply": "2023-11-12T04:09:03.026404Z",
     "shell.execute_reply.started": "2023-11-12T03:31:34.545110Z"
    },
    "papermill": {
     "duration": 0.648276,
     "end_time": "2023-11-12T04:09:03.027140",
     "exception": false,
     "start_time": "2023-11-12T04:09:02.378864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# reading the files\n",
    "df_eng_train = read_text(eng_train)\n",
    "df_ko_train = read_text(ko_train)\n",
    "\n",
    "df_eng_test = read_text(eng_test)\n",
    "df_ko_test = read_text(ko_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feabaa6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:03.131280Z",
     "iopub.status.busy": "2023-11-12T04:09:03.130437Z",
     "iopub.status.idle": "2023-11-12T04:09:03.134169Z",
     "shell.execute_reply": "2023-11-12T04:09:03.134660Z",
     "shell.execute_reply.started": "2023-11-12T03:31:35.215807Z"
    },
    "papermill": {
     "duration": 0.058679,
     "end_time": "2023-11-12T04:09:03.134806",
     "exception": false,
     "start_time": "2023-11-12T04:09:03.076127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166215, 166215, 1982, 1982)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at the length of the different datasets\n",
    "\n",
    "len(df_eng_train) , len(df_ko_train) , len(df_eng_test) , len(df_ko_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b597392",
   "metadata": {
    "papermill": {
     "duration": 0.04856,
     "end_time": "2023-11-12T04:09:03.231998",
     "exception": false,
     "start_time": "2023-11-12T04:09:03.183438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "1. Remove punctuation\n",
    "2. To lower case\n",
    "3. Remove new line charecters\n",
    "4. Split into indivisual words\n",
    "5. Build vocabulary of English and Korean Language \n",
    "     - index2word\n",
    "     - word2index\n",
    "6. Encoding and Padding each sentences from both language\n",
    "7. Prepare train/test batches of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "980e1066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:03.399102Z",
     "iopub.status.busy": "2023-11-12T04:09:03.363369Z",
     "iopub.status.idle": "2023-11-12T04:09:05.282776Z",
     "shell.execute_reply": "2023-11-12T04:09:05.282170Z",
     "shell.execute_reply.started": "2023-11-12T03:31:35.224921Z"
    },
    "papermill": {
     "duration": 2.001813,
     "end_time": "2023-11-12T04:09:05.282940",
     "exception": false,
     "start_time": "2023-11-12T04:09:03.281127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "df_eng_train = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_eng_train]\n",
    "df_ko_train = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_ko_train]\n",
    "df_eng_test = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_eng_test]\n",
    "df_ko_test = [s.translate(str.maketrans('', '', string.punctuation)) for s in df_ko_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da07f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:05.388946Z",
     "iopub.status.busy": "2023-11-12T04:09:05.388160Z",
     "iopub.status.idle": "2023-11-12T04:09:05.391609Z",
     "shell.execute_reply": "2023-11-12T04:09:05.391112Z",
     "shell.execute_reply.started": "2023-11-12T03:31:37.210817Z"
    },
    "papermill": {
     "duration": 0.05755,
     "end_time": "2023-11-12T04:09:05.391736",
     "exception": false,
     "start_time": "2023-11-12T04:09:05.334186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'And were going to tell you some stories from the sea here in video \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at one of the sentence\n",
    "df_eng_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02b4bc55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:05.497023Z",
     "iopub.status.busy": "2023-11-12T04:09:05.496185Z",
     "iopub.status.idle": "2023-11-12T04:09:05.499875Z",
     "shell.execute_reply": "2023-11-12T04:09:05.499244Z",
     "shell.execute_reply.started": "2023-11-12T03:31:37.218022Z"
    },
    "papermill": {
     "duration": 0.058756,
     "end_time": "2023-11-12T04:09:05.500000",
     "exception": false,
     "start_time": "2023-11-12T04:09:05.441244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: Applause David Gallo This is Bill Lange Im Dave Gallo \n",
      " Koren: 박수 이쪽은 Bill Lange 이고 저는 David Gallo입니다 \n",
      "\n",
      "English: And were going to tell you some stories from the sea here in video \n",
      " Koren: 우리는 여러분에게 바닷속 이야기를 영상과 함께 들려주고자 합니다 \n",
      "\n",
      "English: Weve got some of the most incredible video of Titanic thats ever been seen and were not going to show you any of it \n",
      " Koren: 저희는 끝내주는 타이타닉 비디오도 있긴 합니다만 뭐여기서는 눈꼽만큼도 보여줄 생각이없습니다 \n",
      "\n",
      "English: Laughter The truth of the matter is that the Titanic  even though its breaking all sorts of box office records  its not the most exciting story from the sea \n",
      " Koren: 웃음 비록 타이타닉이 박스오피스에서 굉장한 실적을 거두긴 했지만 바다가 들려주는 이야기 중 가장 재밌는 것은 아닙니다 \n",
      "\n",
      "English: And the problem I think is that we take the ocean for granted \n",
      " Koren: 문제라면 우리는 우리가 바다를 이미 알고있다고 믿는거죠 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking into 5 pair of sentence from both the languages\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"English: {} \\n Koren: {} \\n\".format(df_eng_train[i].strip(), df_ko_train[i].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e14696e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:05.680578Z",
     "iopub.status.busy": "2023-11-12T04:09:05.644239Z",
     "iopub.status.idle": "2023-11-12T04:09:07.021236Z",
     "shell.execute_reply": "2023-11-12T04:09:07.020589Z",
     "shell.execute_reply.started": "2023-11-12T03:31:37.230181Z"
    },
    "papermill": {
     "duration": 1.47176,
     "end_time": "2023-11-12T04:09:07.021387",
     "exception": false,
     "start_time": "2023-11-12T04:09:05.549627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to lower the words and remove new lines charecters\n",
    "for i in range(len(df_eng_train)):\n",
    "    df_eng_train[i] = df_eng_train[i].lower().rstrip(\"\\n\").split()\n",
    "    df_ko_train[i] = df_ko_train[i].lower().rstrip(\"\\n\").split()\n",
    "    \n",
    "for i in range(len(df_eng_test)):\n",
    "    df_eng_test[i] = df_eng_test[i].lower().rstrip(\"\\n\").split()\n",
    "    df_ko_test[i] = df_ko_test[i].lower().rstrip(\"\\n\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb60e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:07.126856Z",
     "iopub.status.busy": "2023-11-12T04:09:07.126110Z",
     "iopub.status.idle": "2023-11-12T04:09:07.129622Z",
     "shell.execute_reply": "2023-11-12T04:09:07.129114Z",
     "shell.execute_reply.started": "2023-11-12T03:31:40.002011Z"
    },
    "papermill": {
     "duration": 0.058097,
     "end_time": "2023-11-12T04:09:07.129745",
     "exception": false,
     "start_time": "2023-11-12T04:09:07.071648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and',\n",
       " 'were',\n",
       " 'going',\n",
       " 'to',\n",
       " 'tell',\n",
       " 'you',\n",
       " 'some',\n",
       " 'stories',\n",
       " 'from',\n",
       " 'the',\n",
       " 'sea',\n",
       " 'here',\n",
       " 'in',\n",
       " 'video']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at one of the sentence after the inital preprocess\n",
    "df_eng_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5efe70cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:07.238773Z",
     "iopub.status.busy": "2023-11-12T04:09:07.238131Z",
     "iopub.status.idle": "2023-11-12T04:09:07.241041Z",
     "shell.execute_reply": "2023-11-12T04:09:07.240520Z",
     "shell.execute_reply.started": "2023-11-11T13:14:50.953670Z"
    },
    "papermill": {
     "duration": 0.060165,
     "end_time": "2023-11-12T04:09:07.241164",
     "exception": false,
     "start_time": "2023-11-12T04:09:07.180999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # bulding the vocabulary for English and Korean Language\n",
    "# # first we will build the index 2 word mapping\n",
    "\n",
    "\n",
    "# en_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"] # <PAD> will be the zero'th index\n",
    "# ko_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
    "\n",
    "# for ds in [df_eng_train , df_eng_test]:\n",
    "#     for sentence in ds:\n",
    "#         for token in sentence:\n",
    "#             if token not in en_index2word:\n",
    "#                 en_index2word.append(token)\n",
    "\n",
    "# print('English index to word done')                \n",
    "                \n",
    "# for ds in [df_ko_train , df_ko_test]:\n",
    "#     for sentence in ds:\n",
    "#         for token in sentence:\n",
    "#             if token not in ko_index2word:\n",
    "#                 ko_index2word.append(token)\n",
    "\n",
    "# print('Koren index to word done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "965aa1fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:07.347623Z",
     "iopub.status.busy": "2023-11-12T04:09:07.347023Z",
     "iopub.status.idle": "2023-11-12T04:09:07.349745Z",
     "shell.execute_reply": "2023-11-12T04:09:07.349221Z"
    },
    "papermill": {
     "duration": 0.058197,
     "end_time": "2023-11-12T04:09:07.349916",
     "exception": false,
     "start_time": "2023-11-12T04:09:07.291719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # dumping into pickle files for future use\n",
    "# from pickle import dump\n",
    "\n",
    "# dump(en_index2word, open('en_index2word.pkl', 'wb'))\n",
    "# dump(ko_index2word, open('ko_index2word.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fac4f95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:07.456718Z",
     "iopub.status.busy": "2023-11-12T04:09:07.456049Z",
     "iopub.status.idle": "2023-11-12T04:09:07.727152Z",
     "shell.execute_reply": "2023-11-12T04:09:07.727664Z",
     "shell.execute_reply.started": "2023-11-12T03:32:12.262933Z"
    },
    "papermill": {
     "duration": 0.326967,
     "end_time": "2023-11-12T04:09:07.727851",
     "exception": false,
     "start_time": "2023-11-12T04:09:07.400884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "\n",
    "en_index2word = load(open('../input/nlpasgn/en_index2word.pkl', 'rb'))\n",
    "ko_index2word = load(open('../input/nlpasgn/ko_index2word.pkl', 'rb'))\n",
    "\n",
    "# building the reverse word2index mapping using index2word dictionaries\n",
    "\n",
    "en_word2idx = {token : idx for idx , token in enumerate(en_index2word)}\n",
    "ko_word2idx = {token : idx for idx , token in enumerate(ko_index2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f3191bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:07.833383Z",
     "iopub.status.busy": "2023-11-12T04:09:07.832543Z",
     "iopub.status.idle": "2023-11-12T04:09:07.835125Z",
     "shell.execute_reply": "2023-11-12T04:09:07.834619Z",
     "shell.execute_reply.started": "2023-11-10T04:32:10.090511Z"
    },
    "papermill": {
     "duration": 0.05655,
     "end_time": "2023-11-12T04:09:07.835259",
     "exception": false,
     "start_time": "2023-11-12T04:09:07.778709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looking the dictionaries and the mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2adb1af0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:07.944451Z",
     "iopub.status.busy": "2023-11-12T04:09:07.943763Z",
     "iopub.status.idle": "2023-11-12T04:09:07.947305Z",
     "shell.execute_reply": "2023-11-12T04:09:07.946854Z",
     "shell.execute_reply.started": "2023-11-12T03:32:16.107346Z"
    },
    "papermill": {
     "duration": 0.0615,
     "end_time": "2023-11-12T04:09:07.947453",
     "exception": false,
     "start_time": "2023-11-12T04:09:07.885953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('이고', 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_index2word[7] , ko_word2idx['이고']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e41e6f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:08.063556Z",
     "iopub.status.busy": "2023-11-12T04:09:08.062572Z",
     "iopub.status.idle": "2023-11-12T04:09:08.066228Z",
     "shell.execute_reply": "2023-11-12T04:09:08.066785Z",
     "shell.execute_reply.started": "2023-11-12T03:32:18.082346Z"
    },
    "papermill": {
     "duration": 0.066936,
     "end_time": "2023-11-12T04:09:08.066941",
     "exception": false,
     "start_time": "2023-11-12T04:09:08.000005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gallo', 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_index2word[5] , en_word2idx['gallo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7c455cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:08.255944Z",
     "iopub.status.busy": "2023-11-12T04:09:08.222034Z",
     "iopub.status.idle": "2023-11-12T04:09:08.259422Z",
     "shell.execute_reply": "2023-11-12T04:09:08.258942Z",
     "shell.execute_reply.started": "2023-11-12T03:32:20.482093Z"
    },
    "papermill": {
     "duration": 0.127493,
     "end_time": "2023-11-12T04:09:08.259558",
     "exception": false,
     "start_time": "2023-11-12T04:09:08.132065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English : 17.39973528261589\n",
      "Korean : 12.162939566224468\n"
     ]
    }
   ],
   "source": [
    "# Average sentence length in Training dataset for both the languages\n",
    "\n",
    "print('English :',sum([len(sent) for sent in df_eng_train])/len(df_eng_train))\n",
    "\n",
    "print('Korean :',sum([len(sent) for sent in df_ko_train])/len(df_ko_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dad3be9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:08.367531Z",
     "iopub.status.busy": "2023-11-12T04:09:08.366664Z",
     "iopub.status.idle": "2023-11-12T04:09:08.368832Z",
     "shell.execute_reply": "2023-11-12T04:09:08.369287Z",
     "shell.execute_reply.started": "2023-11-12T03:32:22.882032Z"
    },
    "papermill": {
     "duration": 0.058064,
     "end_time": "2023-11-12T04:09:08.369451",
     "exception": false,
     "start_time": "2023-11-12T04:09:08.311387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# looking the average sentence lengths we are setting the seq length to max 25\n",
    "seq_length = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8836b178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:08.488615Z",
     "iopub.status.busy": "2023-11-12T04:09:08.487991Z",
     "iopub.status.idle": "2023-11-12T04:09:08.490204Z",
     "shell.execute_reply": "2023-11-12T04:09:08.490643Z",
     "shell.execute_reply.started": "2023-11-12T03:32:24.742362Z"
    },
    "papermill": {
     "duration": 0.069013,
     "end_time": "2023-11-12T04:09:08.490790",
     "exception": false,
     "start_time": "2023-11-12T04:09:08.421777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We will do encoding(using word2index mapping) and padding for each sentence to the max seq_length\n",
    "\n",
    "def encoding_padding(vocab , sentence , max_sent_length):\n",
    "    \n",
    "    SOS = [vocab[\"<SOS>\"]] # we will add start of sentence and end of sentence token at each sentence\n",
    "    EOS = [vocab[\"<EOS>\"]]\n",
    "    PAD = [vocab[\"<PAD>\"]]\n",
    "    \n",
    "    if len(sentence) < (max_sent_length - 2): # -2 is for SOS and EOS\n",
    "        pads = ((max_sent_length - 2) - len(sentence)) * PAD\n",
    "        encoding = [vocab[word] for word in sentence]\n",
    "        return SOS + encoding + EOS + pads\n",
    "    else:\n",
    "        encoding = [vocab[word] for word in sentence[:(max_sent_length - 2)]]\n",
    "        return SOS + encoding + EOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b185e3",
   "metadata": {
    "papermill": {
     "duration": 0.052804,
     "end_time": "2023-11-12T04:09:08.594970",
     "exception": false,
     "start_time": "2023-11-12T04:09:08.542166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Preparing training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b9e9de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:08.714463Z",
     "iopub.status.busy": "2023-11-12T04:09:08.709219Z",
     "iopub.status.idle": "2023-11-12T04:09:12.443956Z",
     "shell.execute_reply": "2023-11-12T04:09:12.443324Z",
     "shell.execute_reply.started": "2023-11-12T03:32:29.282098Z"
    },
    "papermill": {
     "duration": 3.796339,
     "end_time": "2023-11-12T04:09:12.444095",
     "exception": false,
     "start_time": "2023-11-12T04:09:08.647756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoding every sentence in train and test\n",
    "encoded_train_en = [encoding_padding(en_word2idx,sent,seq_length) for sent in df_eng_train]\n",
    "encoded_train_ko = [encoding_padding(ko_word2idx,sent,seq_length) for sent in df_ko_train]\n",
    "encoded_test_en = [encoding_padding(en_word2idx,sent,seq_length) for sent in df_eng_test]\n",
    "encoded_test_ko = [encoding_padding(ko_word2idx,sent,seq_length) for sent in df_ko_test]\n",
    "\n",
    "# creating numpy array for train and test\n",
    "train_x = np.array(encoded_train_en)\n",
    "train_y = np.array(encoded_train_ko)\n",
    "\n",
    "test_x = np.array(encoded_test_en)\n",
    "test_y = np.array(encoded_test_ko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5516a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:12.553281Z",
     "iopub.status.busy": "2023-11-12T04:09:12.552428Z",
     "iopub.status.idle": "2023-11-12T04:09:12.554612Z",
     "shell.execute_reply": "2023-11-12T04:09:12.555050Z"
    },
    "papermill": {
     "duration": 0.057971,
     "end_time": "2023-11-12T04:09:12.555198",
     "exception": false,
     "start_time": "2023-11-12T04:09:12.497227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #creating pickles for future use\n",
    "\n",
    "# dump(train_x, open('train_x.pkl', 'wb'))\n",
    "# dump(train_y, open('train_y.pkl', 'wb'))\n",
    "# dump(test_x, open('test_x.pkl', 'wb'))\n",
    "# dump(test_y, open('test_y.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "223d32f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:12.663014Z",
     "iopub.status.busy": "2023-11-12T04:09:12.662328Z",
     "iopub.status.idle": "2023-11-12T04:09:12.664903Z",
     "shell.execute_reply": "2023-11-12T04:09:12.664431Z",
     "shell.execute_reply.started": "2023-11-11T12:30:16.309210Z"
    },
    "papermill": {
     "duration": 0.057658,
     "end_time": "2023-11-12T04:09:12.665027",
     "exception": false,
     "start_time": "2023-11-12T04:09:12.607369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # loading the train test numpy array from pickles \n",
    "# train_x = load(open('../input/nlpasgn/train_x.pkl', 'rb'))\n",
    "# train_y = load(open('../input/nlpasgn/train_y.pkl', 'rb'))\n",
    "# test_x = load(open('../input/nlpasgn/test_x.pkl', 'rb'))\n",
    "# test_y = load(open('../input/nlpasgn/test_y.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c68866c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:12.846325Z",
     "iopub.status.busy": "2023-11-12T04:09:12.843894Z",
     "iopub.status.idle": "2023-11-12T04:09:12.849974Z",
     "shell.execute_reply": "2023-11-12T04:09:12.849470Z",
     "shell.execute_reply.started": "2023-11-12T03:32:42.923069Z"
    },
    "papermill": {
     "duration": 0.13305,
     "end_time": "2023-11-12T04:09:12.850100",
     "exception": false,
     "start_time": "2023-11-12T04:09:12.717050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the GPU availability and setting the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a2c7390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:12.961457Z",
     "iopub.status.busy": "2023-11-12T04:09:12.960877Z",
     "iopub.status.idle": "2023-11-12T04:09:12.963586Z",
     "shell.execute_reply": "2023-11-12T04:09:12.963124Z",
     "shell.execute_reply.started": "2023-11-12T03:32:49.663265Z"
    },
    "papermill": {
     "duration": 0.06155,
     "end_time": "2023-11-12T04:09:12.963704",
     "exception": false,
     "start_time": "2023-11-12T04:09:12.902154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the Torch tensor dataloaders\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(train_x) , torch.from_numpy(train_y))\n",
    "test_data = TensorDataset(torch.from_numpy(test_x) , torch.from_numpy(test_y))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dl = DataLoader(train_data,shuffle=True,batch_size=batch_size,drop_last=True)\n",
    "test_dl = DataLoader(test_data,shuffle=True,batch_size=batch_size,drop_last=True)\n",
    "\n",
    "# The drop_last=True parameter ignores the last batch (when the number of examples in your dataset \n",
    "# is not divisible by your batch_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3b89059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:13.076003Z",
     "iopub.status.busy": "2023-11-12T04:09:13.075105Z",
     "iopub.status.idle": "2023-11-12T04:09:13.077891Z",
     "shell.execute_reply": "2023-11-12T04:09:13.077261Z",
     "shell.execute_reply.started": "2023-11-12T03:32:53.752197Z"
    },
    "papermill": {
     "duration": 0.060557,
     "end_time": "2023-11-12T04:09:13.078012",
     "exception": false,
     "start_time": "2023-11-12T04:09:13.017455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_length = target_length = seq_length # setting the sizes\n",
    "\n",
    "SOS = en_word2idx[\"<SOS>\"]\n",
    "EOS = en_word2idx[\"<EOS>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33765488",
   "metadata": {
    "papermill": {
     "duration": 0.052431,
     "end_time": "2023-11-12T04:09:13.183521",
     "exception": false,
     "start_time": "2023-11-12T04:09:13.131090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Building the neural Network\n",
    "We will create the Encoder and Decoder networks , inside them we will use Reccurent Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9b64e87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:13.298097Z",
     "iopub.status.busy": "2023-11-12T04:09:13.297235Z",
     "iopub.status.idle": "2023-11-12T04:09:13.299392Z",
     "shell.execute_reply": "2023-11-12T04:09:13.300010Z",
     "shell.execute_reply.started": "2023-11-12T03:33:00.425048Z"
    },
    "papermill": {
     "duration": 0.064689,
     "end_time": "2023-11-12T04:09:13.300155",
     "exception": false,
     "start_time": "2023-11-12T04:09:13.235466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0) # as we specified padding as zero\n",
    "        \n",
    "        # RNN layer. The input and output are both of the same size \n",
    "        #  since embedding size = hidden size in this example\n",
    "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # The inputs are first transformed into embeddings\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "\n",
    "        # As in any RNN, the new input and the previous hidden states are fed\n",
    "        #  into the model at each time step \n",
    "        output, hidden = self.rnn(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        # This method is used to create the innitial hidden states for the encoder\n",
    "        return torch.zeros(1, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccbd3d6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:13.425432Z",
     "iopub.status.busy": "2023-11-12T04:09:13.424680Z",
     "iopub.status.idle": "2023-11-12T04:09:13.426777Z",
     "shell.execute_reply": "2023-11-12T04:09:13.427258Z",
     "shell.execute_reply.started": "2023-11-12T03:33:06.369279Z"
    },
    "papermill": {
     "duration": 0.072057,
     "end_time": "2023-11-12T04:09:13.427441",
     "exception": false,
     "start_time": "2023-11-12T04:09:13.355384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "\n",
    "        return context, weights\n",
    "\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size)\n",
    "        self.rnn = nn.RNN(2 * hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(seq_length):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                # Teacher forcing: Feed the target as the next input\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
    "            else:\n",
    "                # Without teacher forcing: use its own predictions as the next input\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
    "\n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        output, hidden = self.rnn(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0e57546",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:13.538643Z",
     "iopub.status.busy": "2023-11-12T04:09:13.537984Z",
     "iopub.status.idle": "2023-11-12T04:09:19.153648Z",
     "shell.execute_reply": "2023-11-12T04:09:19.153070Z",
     "shell.execute_reply.started": "2023-11-12T03:33:17.563199Z"
    },
    "papermill": {
     "duration": 5.674168,
     "end_time": "2023-11-12T04:09:19.153791",
     "exception": false,
     "start_time": "2023-11-12T04:09:13.479623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initializing the networks\n",
    "\n",
    "hidden_size = 256\n",
    "encoder = EncoderRNN(len(en_index2word), hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, len(ko_index2word)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a9159e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:19.263009Z",
     "iopub.status.busy": "2023-11-12T04:09:19.262378Z",
     "iopub.status.idle": "2023-11-12T04:09:19.265836Z",
     "shell.execute_reply": "2023-11-12T04:09:19.265286Z",
     "shell.execute_reply.started": "2023-11-12T03:33:23.219205Z"
    },
    "papermill": {
     "duration": 0.06008,
     "end_time": "2023-11-12T04:09:19.265981",
     "exception": false,
     "start_time": "2023-11-12T04:09:19.205901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(53838, 256, padding_idx=0)\n",
      "  (rnn): RNN(256, 256, batch_first=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# looking at the networks\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a8f5200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:19.378777Z",
     "iopub.status.busy": "2023-11-12T04:09:19.378070Z",
     "iopub.status.idle": "2023-11-12T04:09:19.381125Z",
     "shell.execute_reply": "2023-11-12T04:09:19.381677Z",
     "shell.execute_reply.started": "2023-11-12T03:33:25.662506Z"
    },
    "papermill": {
     "duration": 0.061518,
     "end_time": "2023-11-12T04:09:19.381841",
     "exception": false,
     "start_time": "2023-11-12T04:09:19.320323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(295179, 256)\n",
      "  (attention): BahdanauAttention(\n",
      "    (Wa): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (Ua): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (Va): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      "  (rnn): RNN(512, 256, batch_first=True)\n",
      "  (out): Linear(in_features=256, out_features=295179, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e3a51fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:19.494100Z",
     "iopub.status.busy": "2023-11-12T04:09:19.493506Z",
     "iopub.status.idle": "2023-11-12T04:09:19.496415Z",
     "shell.execute_reply": "2023-11-12T04:09:19.495928Z",
     "shell.execute_reply.started": "2023-11-12T03:33:28.622340Z"
    },
    "papermill": {
     "duration": 0.061414,
     "end_time": "2023-11-12T04:09:19.496539",
     "exception": false,
     "start_time": "2023-11-12T04:09:19.435125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # loss function\n",
    "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = 3e-3) #encoder optimizer with models params and Learning rate\n",
    "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = 3e-3) #decoder optimizer with models params and Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144c7f6",
   "metadata": {
    "papermill": {
     "duration": 0.052474,
     "end_time": "2023-11-12T04:09:19.601470",
     "exception": false,
     "start_time": "2023-11-12T04:09:19.548996",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Model Traning for Encoder and Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cef3d48d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:19.714008Z",
     "iopub.status.busy": "2023-11-12T04:09:19.713413Z",
     "iopub.status.idle": "2023-11-12T04:09:19.718273Z",
     "shell.execute_reply": "2023-11-12T04:09:19.717819Z",
     "shell.execute_reply.started": "2023-11-12T03:39:06.143172Z"
    },
    "papermill": {
     "duration": 0.06465,
     "end_time": "2023-11-12T04:09:19.718429",
     "exception": false,
     "start_time": "2023-11-12T04:09:19.653779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "import random\n",
    "\n",
    "def train_epoch(train_dl, encoder, decoder, enc_optimizer,\n",
    "          dec_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for batch in train_dl:\n",
    "        # Assigning the input and sending to device\n",
    "        input_tensor = batch[0].to(device)\n",
    "\n",
    "        # Assigning the output and sending to device\n",
    "        target_tensor = batch[1].to(device)\n",
    "        \n",
    "        # Creating initial hidden states for the encoder\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        # Sending to device \n",
    "        encoder_hidden = encoder_hidden.to(device)\n",
    "\n",
    "        enc_optimizer.zero_grad()\n",
    "        dec_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor , encoder_hidden)\n",
    "        \n",
    "        ### Teacher forcing\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "        if use_teacher_forcing:\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "        else:\n",
    "            decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, None)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        enc_optimizer.step()\n",
    "        dec_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "004afff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:19.835796Z",
     "iopub.status.busy": "2023-11-12T04:09:19.835165Z",
     "iopub.status.idle": "2023-11-12T04:09:19.837810Z",
     "shell.execute_reply": "2023-11-12T04:09:19.837299Z",
     "shell.execute_reply.started": "2023-11-12T03:39:09.822550Z"
    },
    "papermill": {
     "duration": 0.06632,
     "end_time": "2023-11-12T04:09:19.837939",
     "exception": false,
     "start_time": "2023-11-12T04:09:19.771619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "063c3938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:19.952582Z",
     "iopub.status.busy": "2023-11-12T04:09:19.951923Z",
     "iopub.status.idle": "2023-11-12T04:09:19.954295Z",
     "shell.execute_reply": "2023-11-12T04:09:19.954893Z",
     "shell.execute_reply.started": "2023-11-12T03:39:14.862559Z"
    },
    "papermill": {
     "duration": 0.064102,
     "end_time": "2023-11-12T04:09:19.955040",
     "exception": false,
     "start_time": "2023-11-12T04:09:19.890938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, enc_optimizer, dec_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15133e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T04:09:20.068578Z",
     "iopub.status.busy": "2023-11-12T04:09:20.067860Z",
     "iopub.status.idle": "2023-11-12T08:06:12.160707Z",
     "shell.execute_reply": "2023-11-12T08:06:12.161189Z",
     "shell.execute_reply.started": "2023-11-12T03:41:21.712319Z"
    },
    "papermill": {
     "duration": 14212.152624,
     "end_time": "2023-11-12T08:06:12.161371",
     "exception": false,
     "start_time": "2023-11-12T04:09:20.008747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47m 26s (- 189m 46s) (2 20%) 5.3472\n",
      "94m 45s (- 142m 8s) (4 40%) 5.3824\n",
      "142m 5s (- 94m 43s) (6 60%) 5.3798\n",
      "189m 28s (- 47m 22s) (8 80%) 5.5199\n",
      "236m 51s (- 0m 0s) (10 100%) 5.4914\n",
      "CPU times: user 3h 29min 58s, sys: 26min 54s, total: 3h 56min 53s\n",
      "Wall time: 3h 56min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train(train_dl, encoder, decoder, 10, print_every=2, plot_every=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "588e7568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T08:06:12.276252Z",
     "iopub.status.busy": "2023-11-12T08:06:12.275615Z",
     "iopub.status.idle": "2023-11-12T08:06:12.278192Z",
     "shell.execute_reply": "2023-11-12T08:06:12.277697Z",
     "shell.execute_reply.started": "2022-03-05T09:19:23.100395Z"
    },
    "papermill": {
     "duration": 0.060949,
     "end_time": "2023-11-12T08:06:12.278306",
     "exception": false,
     "start_time": "2023-11-12T08:06:12.217357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # saving the models for future use\n",
    "\n",
    "# encoder_path = \"encoder.pth\"\n",
    "# torch.save(encoder, encoder_path)\n",
    "\n",
    "# decoder_path = \"decoder.pth\"\n",
    "# torch.save(decoder, decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70593d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T08:06:12.392261Z",
     "iopub.status.busy": "2023-11-12T08:06:12.391649Z",
     "iopub.status.idle": "2023-11-12T08:06:12.394386Z",
     "shell.execute_reply": "2023-11-12T08:06:12.393776Z",
     "shell.execute_reply.started": "2022-03-08T07:06:04.188093Z"
    },
    "papermill": {
     "duration": 0.060614,
     "end_time": "2023-11-12T08:06:12.394505",
     "exception": false,
     "start_time": "2023-11-12T08:06:12.333891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # load the models\n",
    "# encoder = torch.load('../input/nlpasgn/encoder.pth')\n",
    "# decoder = torch.load('../input/nlpasgn/dencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d8e8a2",
   "metadata": {
    "papermill": {
     "duration": 0.054948,
     "end_time": "2023-11-12T08:06:12.504919",
     "exception": false,
     "start_time": "2023-11-12T08:06:12.449971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Making Predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b193c6fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T08:06:12.623972Z",
     "iopub.status.busy": "2023-11-12T08:06:12.623236Z",
     "iopub.status.idle": "2023-11-12T08:06:12.626153Z",
     "shell.execute_reply": "2023-11-12T08:06:12.625679Z",
     "shell.execute_reply.started": "2023-11-12T04:04:56.855688Z"
    },
    "papermill": {
     "duration": 0.066032,
     "end_time": "2023-11-12T08:06:12.626271",
     "exception": false,
     "start_time": "2023-11-12T08:06:12.560239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_predictions(test_sentence):\n",
    "    with torch.no_grad():\n",
    "        # Tokenizing, Encoding, transforming to Tensor\n",
    "        test_sentence = torch.tensor(encoding_padding(en_word2idx, test_sentence, seq_length)).unsqueeze(dim=0)\n",
    "    \n",
    "        encoder_hidden = torch.zeros(1, 1, hidden_size) # initial input to encoder\n",
    "        encoder_hidden = encoder_hidden.to(device) # taking to the device\n",
    "\n",
    "        input_tensor = test_sentence.to(device) # taking to the device\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor,encoder_hidden)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS:\n",
    "                break\n",
    "            decoded_words.append(ko_index2word[idx.to('cpu').item()])\n",
    "    return decoded_words[1:] # not inclusding SOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef44748b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T08:06:12.741649Z",
     "iopub.status.busy": "2023-11-12T08:06:12.740800Z",
     "iopub.status.idle": "2023-11-12T08:06:13.030165Z",
     "shell.execute_reply": "2023-11-12T08:06:13.030620Z",
     "shell.execute_reply.started": "2023-11-12T04:04:56.873919Z"
    },
    "papermill": {
     "duration": 0.349628,
     "end_time": "2023-11-12T08:06:13.030783",
     "exception": false,
     "start_time": "2023-11-12T08:06:12.681155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Number in test set: ---------- 0 ---------------\n",
      "\n",
      "Actual English Sentence :  allison hunt my three minutes hasnt started yet has it\n",
      "Translated Predictions: ['그리고', '이', '킹스']\n",
      "Actual Sentence: ['아직', '3분', '시작된', '건', '아니죠', '그렇죠']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 1 ---------------\n",
      "\n",
      "Actual English Sentence :  chris anderson no you cant start the three minutes\n",
      "Translated Predictions: ['그리고', '이', '킹스']\n",
      "Actual Sentence: ['크리스', '앤더슨네', '맘대로', '시작하실', '수', '없습니다']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 2 ---------------\n",
      "\n",
      "Actual English Sentence :  reset the three minutes thats just not fair\n",
      "Translated Predictions: ['그리고', '이', '킹스']\n",
      "Actual Sentence: ['3분', '다시', '설정해주세요', '이건', '반칙입니다']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 3 ---------------\n",
      "\n",
      "Actual English Sentence :  ah oh my god its harsh up here\n",
      "Translated Predictions: ['그리고', '저는']\n",
      "Actual Sentence: ['앨리슨', '헌트', '어머나', '여기', '참', '냉정하네요']\n",
      "\n",
      "\n",
      "Sentence Number in test set: ---------- 4 ---------------\n",
      "\n",
      "Actual English Sentence :  i mean im nervous enough as it is\n",
      "Translated Predictions: ['그리고', '이', '킹스']\n",
      "Actual Sentence: ['정말이지', '긴장되네요']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('Sentence Number in test set: ----------', i, '---------------\\n')\n",
    "    print('Actual English Sentence : ',\" \".join(df_eng_test[i]))\n",
    "    print('Translated Predictions:' , make_predictions(df_eng_test[i]))\n",
    "    print('Actual Sentence:' , df_ko_test[i])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "00332c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T08:06:13.150710Z",
     "iopub.status.busy": "2023-11-12T08:06:13.149972Z",
     "iopub.status.idle": "2023-11-12T08:06:13.243016Z",
     "shell.execute_reply": "2023-11-12T08:06:13.243465Z",
     "shell.execute_reply.started": "2023-11-12T04:04:57.188361Z"
    },
    "papermill": {
     "duration": 0.156977,
     "end_time": "2023-11-12T08:06:13.243617",
     "exception": false,
     "start_time": "2023-11-12T08:06:13.086640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "# https://pytorch.org/text/stable/data_metrics.html\n",
    "\n",
    "def bleu(src_data, tar_data):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "    for i in zip(src_data , tar_data):\n",
    "        src = i[0]\n",
    "        trg = i[1]\n",
    "        prediction = make_predictions(src)\n",
    "        targets.append([str(ko_word2idx[word]) for word in trg])\n",
    "        outputs.append([str(ko_word2idx[word]) for word in prediction])\n",
    "    return bleu_score(outputs, targets,max_n=1,weights=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc758cf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T08:06:13.359443Z",
     "iopub.status.busy": "2023-11-12T08:06:13.358847Z",
     "iopub.status.idle": "2023-11-12T08:08:03.800551Z",
     "shell.execute_reply": "2023-11-12T08:08:03.801052Z",
     "shell.execute_reply.started": "2023-11-12T04:04:57.281292Z"
    },
    "papermill": {
     "duration": 110.501618,
     "end_time": "2023-11-12T08:08:03.801219",
     "exception": false,
     "start_time": "2023-11-12T08:06:13.299601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score 4.33\n"
     ]
    }
   ],
   "source": [
    "# Bleu score on test dataset\n",
    "score = bleu(df_eng_test,df_ko_test)\n",
    "print(f\"Bleu score {score*100:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14355.769965,
   "end_time": "2023-11-12T08:08:06.543443",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-12T04:08:50.773478",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
