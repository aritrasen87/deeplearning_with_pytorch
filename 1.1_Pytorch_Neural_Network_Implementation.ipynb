{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section with one sample example we saw how to train a Neural Network from scratch. In this notebook we'll use nn.Module and nn.Parameter along with autograd, optim utility packages provided within PyTorch. We subclass nn.Module (which itself is a class and able to keep track of state). nn.Module has a number of attributes and methods (such as .parameters() and .zero_grad()) which we will be using to perform different operations required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial ,  we will create a Deep Learning model for building a handwritten digit classifier. We will make use of the MNIST dataset included in the torchvision package.\n",
    " \n",
    "<b>Data Preprocessing</b>:\n",
    "\n",
    " Mandatory first step is to do the basic data pre-processing steps , using the a utility called <b>transforms</b> which comes from torchvision package.\n",
    " \n",
    " We will do two below mentioned basic data preprocessing operations (this will be explained more detail in case of CNN tutorial).\n",
    " \n",
    "- Transform the raw dataset into tensors.\n",
    "- Normalize the dataset.\n",
    "\n",
    "We will also import the dataset from torch vision package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the training\n",
    "train_data = MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of train data\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader helps us to create batches of data , we will go deeper into DataLoader in next tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# data loader preparation\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Let's check the shape of the input/target data\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking an sample image , data\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing it for prediction , once the model is trained\n",
    "img_zero = images[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see that input data is not flattened to pass through the linear layers. Network can only accept a vector. \n",
    "\n",
    "So we will need to reshape the batch in a format of (batch size , no of features).\n",
    "\n",
    "number of features -> 1 * 28 * 28 = 784\n",
    "\n",
    "Shape of target data is as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture\n",
    "\n",
    "We create a new class (which inherits the properties from the base class from nn package called Module) to define the archietecture of the Neural Network. \n",
    "\n",
    "- Layer defination should be inside the constructor of the class.\n",
    "- Forward propagation step should be included inside forward method.\n",
    "\n",
    "Activations(Relu,Sigmoid,Tanh etc) and loss functions(cross entropy,nllloss etc) comes from torch.nn.functional. This module contains all the functions in the torch.nn module.\n",
    "\n",
    "Syntax of nn.Linear() is (input size, output size)\n",
    "\n",
    "This NN architecture below represents the 784 nodes (28*28 pixels) in the input layer, 256 in the hidden layer, and 10 in the output layer(0-9 numbers). Inside the forward function, we will use the relu activation function in the hidden layer which present under torch.nn.functional module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input tensor is flattened \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the loss and optimizer functions\n",
    "\n",
    "- <b>Loss Function</b> : Here we have used the CrossEntropyLoss() function.Generally loss assigned to `criterion`. for MNIST classification , we generally use softmax function to predict class probabilities. With a softmax output, you want to use cross-entropy as the loss.\n",
    "\n",
    "Few things to keep in mind while using the CrossEntropyLoss() in Pytorch \n",
    "\n",
    "    - CrossEntropyLoss criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n",
    "    - The input is expected to contain scores for each class.\n",
    "\n",
    "This means we need to pass in the raw output of our network into the loss, not the output of the softmax function.That's why there is no activation after self.fc2(x).\n",
    "\n",
    "Here is a great article to understand Pytorch's Loss functions from scratch - https://medium.com/@zhang_yang/pytorch-loss-funtions-in-plain-python-b79c05f8b53f\n",
    "\n",
    "- <b>Optimizer</b> : Pytorch also has a package with various optimization algorithms, torch.optim. We can use the step method from our optimizer to take a forward step, instead of manually updating each parameter.Below are the few availavle optimizer in pytorch -\n",
    "\n",
    "    - optim.Adam\n",
    "    - optim.RMSprop\n",
    "    - optim.SGD\n",
    "    - optim.Adagrad\n",
    "\n",
    "Learn more about optimizers from Andrew Ng- https://www.youtube.com/watch?v=4qJaSmvhxi8&list=PL9fbVgKf1HGwmWyfsc14iMsBSsluM5bCP\n",
    "\n",
    "In the optimizer we need to pass model parameters(can be accesed using model.parameters()) for the back propagation operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Traning the Model:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss:  0.6522858945839107\n",
      "Epoch: 2 Training Loss:  0.3400297284250458\n",
      "Epoch: 3 Training Loss:  0.2977698540516819\n",
      "Epoch: 4 Training Loss:  0.26874281287193297\n",
      "Epoch: 5 Training Loss:  0.24427759759438536\n",
      "Epoch: 6 Training Loss:  0.22300724969400715\n",
      "Epoch: 7 Training Loss:  0.2044730270622919\n",
      "Epoch: 8 Training Loss:  0.18847376090784868\n",
      "Epoch: 9 Training Loss:  0.1745395333141399\n",
      "Epoch: 10 Training Loss:  0.16248214037933698\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11): ## run the model for 10 epochs\n",
    "    train_loss = []\n",
    "    \n",
    "    ## training part \n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        ## 1. forward propagation\n",
    "        output = model(data)\n",
    "        \n",
    "        ## 2. loss calculation\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        ## 3. backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 4. weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few Steps to note:\n",
    "\n",
    "- <b>optimizer.zero_grad()</b>: - will zero out the gradients from previous traning step , in this way gradients won't be   accumulated. This should be done before calculating the gradients at each epoch.\n",
    "- <b>criterion(output, target)</b>: - we feed in the model predicted values along with actual values to calculate the loss.\n",
    "- <b>optimizer.step()</b>: Once we call loss.backward() , gradients will be calculated and we will use this gradients to update the weights in this step using the learning rate defined in optim.SGD(model.parameters(), lr=0.01)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model with F.log_softmax + nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # make sure input tensor is flattened\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.log_softmax(self.fc4(x), dim=1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss:  0.37074759137739116\n",
      "Epoch: 2 Training Loss:  0.1929439957527211\n",
      "Epoch: 3 Training Loss:  0.15418797801214776\n",
      "Epoch: 4 Training Loss:  0.13239779170330923\n",
      "Epoch: 5 Training Loss:  0.12347747919235795\n",
      "Epoch: 6 Training Loss:  0.11238287260498812\n",
      "Epoch: 7 Training Loss:  0.10532260832308869\n",
      "Epoch: 8 Training Loss:  0.09786521852752533\n",
      "Epoch: 9 Training Loss:  0.09384211948209364\n",
      "Epoch: 10 Training Loss:  0.08986101426683793\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 6): ## run the model for 5 epochs\n",
    "    train_loss = []\n",
    "    \n",
    "    ## training part \n",
    "    \n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        ## 1. forward propagation\n",
    "        output = model(data)\n",
    "        \n",
    "        ## 2. loss calculation\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        ## 3. backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 4. weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now how to do Prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the class probabilities (softmax) for img\n",
    "ps = torch.exp(model(img_zero))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 6.5719e-31, 8.2037e-13, 1.3680e-14, 1.0173e-23, 3.3625e-14,\n",
      "         8.8401e-13, 1.7751e-15, 7.8653e-21, 1.6690e-12]],\n",
      "       grad_fn=<ExpBackward>)\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "print(ps)\n",
    "print(ps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the probabilities, we can get the most likely class using the ps.topk method. This returns the  ùëò  highest values. Since we just want the most likely class, we can use ps.topk(1). This returns a tuple of the top- ùëò  values and the top- ùëò  indices. If the highest value is the fifth element, we'll get back 4 as the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_p, top_class = ps.topk(1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<TopkBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
