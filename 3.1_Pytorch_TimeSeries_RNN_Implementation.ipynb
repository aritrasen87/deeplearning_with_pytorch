{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit : https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location of source file\n",
    "file = 'C:/Users/ENSIEAR/Documents/VS_Code/RNN/raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No  year  month  day  hour  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "0   1  2010      1    1     0    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "1   2  2010      1    1     1    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2   3  2010      1    1     2    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "3   4  2010      1    1     3    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "4   5  2010      1    1     4    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Pre-processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pm2.5 column  contains NA values for the first 24 hours(first 24 hours data will be removed) , also we need to have a single date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(x):\n",
    "    return datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = pd.read_csv(file,  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>cbwd</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_month_day_hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 01:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 02:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>6.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 03:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 04:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>1018.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>12.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     No  pm2.5  DEWP  TEMP    PRES cbwd    Iws  Is  Ir\n",
       "year_month_day_hour                                                   \n",
       "2010-01-01 00:00:00   1    NaN   -21 -11.0  1021.0   NW   1.79   0   0\n",
       "2010-01-01 01:00:00   2    NaN   -21 -12.0  1020.0   NW   4.92   0   0\n",
       "2010-01-01 02:00:00   3    NaN   -21 -11.0  1019.0   NW   6.71   0   0\n",
       "2010-01-01 03:00:00   4    NaN   -21 -14.0  1019.0   NW   9.84   0   0\n",
       "2010-01-01 04:00:00   5    NaN   -20 -12.0  1018.0   NW  12.97   0   0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No column is not required and will be dropped from the dataset.\n",
    "2. Need to set meaning full column names.\n",
    "3. Rename the index column as date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('No', axis=1, inplace=True)\n",
    "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "dataset.index.name = 'date'\n",
    "# mark all NA values with 0\n",
    "dataset['pollution'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "dataset = dataset[24:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43800, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_dir</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-12-31 19:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-23</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>231.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 20:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>237.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 21:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>242.70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 22:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>-22</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>246.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-12-31 23:00:00</th>\n",
       "      <td>12.0</td>\n",
       "      <td>-21</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1034.0</td>\n",
       "      <td>NW</td>\n",
       "      <td>249.85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
       "date                                                                          \n",
       "2014-12-31 19:00:00        8.0  -23  -2.0  1034.0      NW   231.97     0     0\n",
       "2014-12-31 20:00:00       10.0  -22  -3.0  1034.0      NW   237.78     0     0\n",
       "2014-12-31 21:00:00       10.0  -22  -3.0  1034.0      NW   242.70     0     0\n",
       "2014-12-31 22:00:00        8.0  -22  -4.0  1034.0      NW   246.72     0     0\n",
       "2014-12-31 23:00:00       12.0  -21  -3.0  1034.0      NW   249.85     0     0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset contains 2010 to 2014 data with 8 columns. We can also see that wnd_dir column needs to have Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SE', 'cv', 'NW', 'NE'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['wnd_dir'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure all data is float\n",
    "values = values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Prepartion for time series RNN Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can formulate the problem as predicting the pollution at the current hour (t) given the pollution measurement and weather conditions at the prior time step or past one hour.\n",
    "\n",
    "Lag features for past one hour has been created using the below function. More details about the function can we found in the link given in function description.\n",
    "\n",
    "Also the function used pandas shift function , one example of Pandas shift function is given below -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data:\n",
      "                     A   B   C   D\n",
      "2000-01-01 00:00:00  1  10  11  12\n",
      "2000-01-01 12:00:00  2  20  22  24\n",
      "2000-01-02 00:00:00  3  30  33  51\n",
      "2000-01-02 12:00:00  4  40  44  36\n",
      "2000-01-03 00:00:00  5  50  55   2\n",
      "With Shift -2:\n",
      "                       A     B     C     D\n",
      "2000-01-01 00:00:00  3.0  30.0  33.0  51.0\n",
      "2000-01-01 12:00:00  4.0  40.0  44.0  36.0\n",
      "2000-01-02 00:00:00  5.0  50.0  55.0   2.0\n",
      "2000-01-02 12:00:00  NaN   NaN   NaN   NaN\n",
      "2000-01-03 00:00:00  NaN   NaN   NaN   NaN\n",
      "With Shift +2:\n",
      "                       A     B     C     D\n",
      "2000-01-01 00:00:00  NaN   NaN   NaN   NaN\n",
      "2000-01-01 12:00:00  NaN   NaN   NaN   NaN\n",
      "2000-01-02 00:00:00  1.0  10.0  11.0  12.0\n",
      "2000-01-02 12:00:00  2.0  20.0  22.0  24.0\n",
      "2000-01-03 00:00:00  3.0  30.0  33.0  51.0\n"
     ]
    }
   ],
   "source": [
    "#Pandas Shift Tutorials - \n",
    "\n",
    "# importing pandas as pd \n",
    "import pandas as pd \n",
    "   \n",
    "# Creating row index values for our data frame \n",
    "# We have taken time frequency to be of 12 hours interval \n",
    "# We are generating five index value using \"period = 5\" parameter \n",
    "   \n",
    "ind = pd.date_range('01 / 01 / 2000', periods = 5, freq ='12H') \n",
    "   \n",
    "# Creating a dataframe with 4 columns \n",
    "# using \"ind\" as the index for our dataframe \n",
    "df1 = pd.DataFrame({\"A\":[1, 2, 3, 4, 5],  \n",
    "                   \"B\":[10, 20, 30, 40, 50], \n",
    "                   \"C\":[11, 22, 33, 44, 55], \n",
    "                   \"D\":[12, 24, 51, 36, 2]},  \n",
    "                    index = ind) \n",
    "  \n",
    "# Print the dataframe \n",
    "print('Raw Data:')\n",
    "print(df1)\n",
    "\n",
    "print('With Shift -2:')\n",
    "print(df1.shift(-2))\n",
    "\n",
    "print('With Shift +2:')\n",
    "print(df1.shift(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Credit - https://machinelearningmastery.com/convert-time-series-supervised-learning-problem-python/\n",
    "    \n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    \n",
    "    Arguments:\n",
    "    data: Sequence of observations as a list or NumPy array.\n",
    "    n_in: Number of lag observations as input (X).\n",
    "    n_out: Number of observations as output (y).\n",
    "    dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    \n",
    "    Returns:\n",
    "    Pandas DataFrame of series framed for supervised learning.\n",
    "    \n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed = series_to_supervised(scaled, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
       "1   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "2   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "3   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "4   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "5   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "\n",
       "   var7(t-1)  var8(t-1)   var1(t)   var2(t)   var3(t)   var4(t)   var5(t)  \\\n",
       "1   0.000000        0.0  0.148893  0.367647  0.245902  0.527273  0.666667   \n",
       "2   0.000000        0.0  0.159960  0.426471  0.229508  0.545454  0.666667   \n",
       "3   0.000000        0.0  0.182093  0.485294  0.229508  0.563637  0.666667   \n",
       "4   0.037037        0.0  0.138833  0.485294  0.229508  0.563637  0.666667   \n",
       "5   0.074074        0.0  0.109658  0.485294  0.213115  0.563637  0.666667   \n",
       "\n",
       "    var6(t)   var7(t)  var8(t)  \n",
       "1  0.003811  0.000000      0.0  \n",
       "2  0.005332  0.000000      0.0  \n",
       "3  0.008391  0.037037      0.0  \n",
       "4  0.009912  0.074074      0.0  \n",
       "5  0.011433  0.111111      0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
      "2   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
      "3   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
      "4   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
      "5   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
      "\n",
      "   var7(t-1)  var8(t-1)   var1(t)  \n",
      "1   0.000000        0.0  0.148893  \n",
      "2   0.000000        0.0  0.159960  \n",
      "3   0.000000        0.0  0.182093  \n",
      "4   0.037037        0.0  0.138833  \n",
      "5   0.074074        0.0  0.109658  \n"
     ]
    }
   ],
   "source": [
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var1(t) is the target column , or the value we will try to predict.\n",
    "\n",
    "For the simplicity we will train our model with first one year data and we will test our model with remaining dataset.Vice versa also can be tried out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1, 8) (8760,) (35039, 1, 8) (35039,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, sequence length, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence length is one becauase we are only passing past one hour data to predict the pollution of the next hour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will convert the predictors and target values as pytorch Tensors and also we will create batches using Pytorch's data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "x_train = torch.tensor(train_X , dtype=torch.float)\n",
    "y_train = torch.tensor(train_y, dtype=torch.float)\n",
    "x_test = torch.tensor(test_X , dtype=torch.float)\n",
    "y_test = torch.tensor(test_y , dtype=torch.float)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([256, 1, 8])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Let's check the shape of the input/target data\n",
    "dataiter = iter(train_loader)\n",
    "data, target = dataiter.next()\n",
    "print(type(data))\n",
    "print(data.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the RNN class with one layer of RNN with 512 hidden dimension and with one linear transformation in the output layer.\n",
    "\n",
    "Required signatures to be keep in mind -\n",
    "\n",
    "1. RNN - nn.RNN(input_size, hidden_dim, n_layers, batch_first=True) , n_layers is no of stacked RNNs\n",
    "2. Input data x shape - (batch_size, seq_length, input_size)\n",
    "3. Output of RNN is r_out and hidden \n",
    "4. shape of r_out - (batch_size, time_step, hidden_dim)\n",
    "5. shape of hidden - (n_layers, batch_size, hidden_dim)\n",
    "\n",
    "Before feeding the output of RNNs to the linean layer , shape needs to be reshaped as \n",
    "- (batch_size, seq_length*hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers,seq_length):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.n_time_stamps = seq_length\n",
    "\n",
    "        # define an RNN with specified parameters\n",
    "        # batch_first means that the first dim of the input and output will be the batch_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
    "        \n",
    "        # last, fully-connected layer\n",
    "        self.fc = nn.Linear(seq_length*hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # get RNN outputs\n",
    "        r_out, hidden = self.rnn(x, hidden)\n",
    "\n",
    "        # shape output to the linear layer (batch_size, seq_length*hidden_dim)\n",
    "        r_out = r_out.contiguous().view(batch_size,-1)  \n",
    "\n",
    "        # get final output \n",
    "        output = self.fc(r_out)\n",
    "        \n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide on parameters\n",
    "input_size=8\n",
    "output_size=1\n",
    "hidden_dim=512\n",
    "n_layers=1\n",
    "seq_length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(8, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate an RNN\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers , seq_length)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss and Adam optimizer with a learning rate of 0.0001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.0001) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 0 Training Loss:  0.009287049069398028\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 1 Training Loss:  0.007951364948359482\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 2 Training Loss:  0.007052509846877964\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 3 Training Loss:  0.006493238643195261\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 4 Training Loss:  0.006256303996505106\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 5 Training Loss:  0.006746564645950189\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 6 Training Loss:  0.009060627722647041\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 7 Training Loss:  0.012209891321082763\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 8 Training Loss:  0.010260309263899484\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 9 Training Loss:  0.006911892608246382\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 10 Training Loss:  0.005370904157376464\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 11 Training Loss:  0.004818227891947198\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 12 Training Loss:  0.0044557765187859975\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 13 Training Loss:  0.004144261567168595\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 14 Training Loss:  0.0038567582412403732\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 15 Training Loss:  0.003589837479761199\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 16 Training Loss:  0.0033446193898699302\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 17 Training Loss:  0.0031215894474264454\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 18 Training Loss:  0.0029200996505096555\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 19 Training Loss:  0.0027385867878739886\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 20 Training Loss:  0.00257447300485664\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 21 Training Loss:  0.002424104219672325\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 22 Training Loss:  0.00228307003956562\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 23 Training Loss:  0.002146887601531275\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 24 Training Loss:  0.002011830685660243\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 25 Training Loss:  0.001875744478585308\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 26 Training Loss:  0.0017391361556399394\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 27 Training Loss:  0.0016078867381164694\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 28 Training Loss:  0.0015014074545915185\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 1, 8])\n",
      "Epoch: 29 Training Loss:  0.0014756012259407297\n"
     ]
    }
   ],
   "source": [
    "hidden = None # initial hidden\n",
    "for epoch in range(30): ## run the model for 30 epochs\n",
    "    train_loss = []\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "\n",
    "        if data.shape[0] != batch_size:   # to verify if the batch no is 256 or not\n",
    "            print('Batch Size Validation- Input shape Issue:',format(data.shape))\n",
    "            continue\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            ## 1. forward propagation\n",
    "            prediction, hidden = rnn(data, hidden)\n",
    "\n",
    "\n",
    "            ## Representing Memory ##\n",
    "            # make a new variable for hidden and detach the hidden state from its history\n",
    "            # this way, we don't backpropagate through the entire history\n",
    "            hidden = hidden.data\n",
    "            batch_size = data.shape[0]\n",
    "\n",
    "            ## 2. loss calculation\n",
    "            loss = criterion(prediction.squeeze(), target)    # squeeze (256,1) -> (256) - to match target shape\n",
    "            \n",
    "            ## 3. backward propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            ## 4. weight optimization\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Test set performence or Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35039, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction using tensor of predictors i.e x_test\n",
    "yhat , _ = rnn(x_test, None) # throwing away _ the hidden \n",
    "\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to convert yhat to numpy\n",
    "yhat = yhat.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (35039, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yhat) , yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35039, 1, 8)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of target value\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35039, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To invert scale we need to reshape the 3D array to 2D array\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat.reshape(-1,1), test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 37.338\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train On Multiple Lag Timesteps Example\n",
    "We will use 3 hours of data as input. As stated in the blog post -\n",
    "\n",
    "We need to be more careful in specifying the column for input and output.\n",
    "\n",
    "We have 3 * 8 + 8 columns in our framed dataset. We will take 3 * 8 or 24 columns as input for the obs of all features across the previous 3 hours. We will take just the pollution variable as output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file)\n",
    "def parse(x):\n",
    "    return datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = pd.read_csv(file,  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "dataset.drop('No', axis=1, inplace=True)\n",
    "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "dataset.index.name = 'date'\n",
    "# mark all NA values with 0\n",
    "dataset['pollution'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "dataset = dataset[24:]\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the number of lag hours\n",
    "n_hours = 3\n",
    "n_features = 8\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, n_hours, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-3)</th>\n",
       "      <th>var2(t-3)</th>\n",
       "      <th>var3(t-3)</th>\n",
       "      <th>var4(t-3)</th>\n",
       "      <th>var5(t-3)</th>\n",
       "      <th>var6(t-3)</th>\n",
       "      <th>var7(t-3)</th>\n",
       "      <th>var8(t-3)</th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var6(t-2)</th>\n",
       "      <th>var7(t-2)</th>\n",
       "      <th>var8(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124748</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-3)  var2(t-3)  var3(t-3)  var4(t-3)  var5(t-3)  var6(t-3)  \\\n",
       "3   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "4   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "5   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "6   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "7   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "\n",
       "   var7(t-3)  var8(t-3)  var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  \\\n",
       "3   0.000000        0.0   0.148893   0.367647   0.245902   0.527273   \n",
       "4   0.000000        0.0   0.159960   0.426471   0.229508   0.545454   \n",
       "5   0.000000        0.0   0.182093   0.485294   0.229508   0.563637   \n",
       "6   0.037037        0.0   0.138833   0.485294   0.229508   0.563637   \n",
       "7   0.074074        0.0   0.109658   0.485294   0.213115   0.563637   \n",
       "\n",
       "   var5(t-2)  var6(t-2)  var7(t-2)  var8(t-2)  var1(t-1)  var2(t-1)  \\\n",
       "3   0.666667   0.003811   0.000000        0.0   0.159960   0.426471   \n",
       "4   0.666667   0.005332   0.000000        0.0   0.182093   0.485294   \n",
       "5   0.666667   0.008391   0.037037        0.0   0.138833   0.485294   \n",
       "6   0.666667   0.009912   0.074074        0.0   0.109658   0.485294   \n",
       "7   0.666667   0.011433   0.111111        0.0   0.105634   0.485294   \n",
       "\n",
       "   var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)   var1(t)  \\\n",
       "3   0.229508   0.545454   0.666667   0.005332   0.000000        0.0  0.182093   \n",
       "4   0.229508   0.563637   0.666667   0.008391   0.037037        0.0  0.138833   \n",
       "5   0.229508   0.563637   0.666667   0.009912   0.074074        0.0  0.109658   \n",
       "6   0.213115   0.563637   0.666667   0.011433   0.111111        0.0  0.105634   \n",
       "7   0.213115   0.581818   0.666667   0.014492   0.148148        0.0  0.124748   \n",
       "\n",
       "    var2(t)   var3(t)   var4(t)   var5(t)   var6(t)   var7(t)  var8(t)  \n",
       "3  0.485294  0.229508  0.563637  0.666667  0.008391  0.037037      0.0  \n",
       "4  0.485294  0.229508  0.563637  0.666667  0.009912  0.074074      0.0  \n",
       "5  0.485294  0.213115  0.563637  0.666667  0.011433  0.111111      0.0  \n",
       "6  0.485294  0.213115  0.581818  0.666667  0.014492  0.148148      0.0  \n",
       "7  0.485294  0.229508  0.600000  0.666667  0.017551  0.000000      0.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 24) 8760 (8760,)\n",
      "(8760, 3, 8) (8760,) (35037, 3, 8) (35037,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = n_hours * n_features\n",
    "train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
    "test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
    "print(train_X.shape, len(train_X), train_y.shape)\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], n_hours, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_hours, n_features))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "x_train = torch.tensor(train_X , dtype=torch.float)\n",
    "y_train = torch.tensor(train_y, dtype=torch.float)\n",
    "x_test = torch.tensor(test_X , dtype=torch.float)\n",
    "y_test = torch.tensor(test_y , dtype=torch.float)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 8])\n",
      "torch.Size([256])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Let's check the shape of the input/target data\n",
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    print(target.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide on parameters\n",
    "input_size=8\n",
    "output_size=1\n",
    "hidden_dim=512\n",
    "n_layers=1\n",
    "seq_length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(8, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=1536, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# instantiate an RNN\n",
    "rnn = RNN(input_size, output_size, hidden_dim, n_layers , seq_length)\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss and Adam optimizer with a learning rate of 0.0001\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=0.0001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 0 Training Loss:  0.0079601468408809\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 1 Training Loss:  0.00532056950375109\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 2 Training Loss:  0.004561143824556733\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 3 Training Loss:  0.006887500818051836\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 4 Training Loss:  0.011227845721056355\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 5 Training Loss:  0.006237753571065909\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 6 Training Loss:  0.004455090692157254\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 7 Training Loss:  0.003718995489180088\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 8 Training Loss:  0.0032488409265437547\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 9 Training Loss:  0.0034572301733800594\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 10 Training Loss:  0.0036418852259350173\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 11 Training Loss:  0.0029313953435870215\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 12 Training Loss:  0.002302424268290291\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 13 Training Loss:  0.0022446605178308397\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 14 Training Loss:  0.0028031821215443093\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 15 Training Loss:  0.0033407968106022212\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 16 Training Loss:  0.002632728568963049\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 17 Training Loss:  0.001920960345373982\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 18 Training Loss:  0.0017414704848573927\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 19 Training Loss:  0.001698435005142956\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 20 Training Loss:  0.0017126410110744044\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 21 Training Loss:  0.001796336065608022\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 22 Training Loss:  0.0019221027220791096\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 23 Training Loss:  0.0019288399369757185\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 24 Training Loss:  0.0017333631746142225\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 25 Training Loss:  0.0015461349231533379\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 26 Training Loss:  0.001522401991464636\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 27 Training Loss:  0.0019677094601587776\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 28 Training Loss:  0.0034335781820118427\n",
      "Batch Size Validation- Input shape Issue: torch.Size([56, 3, 8])\n",
      "Epoch: 29 Training Loss:  0.0034786463845247295\n"
     ]
    }
   ],
   "source": [
    "hidden = None # initial hidden\n",
    "for epoch in range(30): ## run the model for 30 epochs\n",
    "    train_loss = []\n",
    "    \n",
    "    for data, target in train_loader:\n",
    "\n",
    "        if data.shape[0] != batch_size:   # to verify if the batch no is 256 or not\n",
    "            print('Batch Size Validation- Input shape Issue:',format(data.shape))\n",
    "            continue\n",
    "        else:\n",
    "            optimizer.zero_grad()\n",
    "            ## 1. forward propagation\n",
    "            prediction, hidden = rnn(data, hidden)\n",
    "\n",
    "\n",
    "            ## Representing Memory ##\n",
    "            # make a new variable for hidden and detach the hidden state from its history\n",
    "            # this way, we don't backpropagate through the entire history\n",
    "            hidden = hidden.data\n",
    "            batch_size = data.shape[0]\n",
    "\n",
    "            ## 2. loss calculation\n",
    "            loss = criterion(prediction.squeeze(), target)    # squeeze (256,1) -> (256) - to match target shape\n",
    "            \n",
    "            ## 3. backward propagation\n",
    "            loss.backward()\n",
    "            \n",
    "            ## 4. weight optimization\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35037, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction using tensor of predictors i.e x_test\n",
    "yhat , _ = rnn(x_test, None) # throwing away _ the hidden \n",
    "\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to convert yhat to numpy and with correct shape\n",
    "yhat = yhat.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (35037, 1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yhat) , yhat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35037, 3, 8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the shape of target value\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35037, 24)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To invert scale we need to reshape the 3D array to 2D array\n",
    "test_X = test_X.reshape(test_X.shape[0], n_hours*n_features)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((yhat.reshape(-1,1), test_X[:, -7:]), axis=1) #Note: -7 to select correct inputs\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, -7:]), axis=1) #Note: -7 to select correct inputs\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 46.668\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE\n",
    "from math import sqrt\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the Jason Brownlee's blog post also , we can also see using multiple time sequence for this problem - the model performence is not getting increased.\n",
    "However , we have learnt how to do RNNs in pytorch with single time sequence and with multiple time sequence. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
