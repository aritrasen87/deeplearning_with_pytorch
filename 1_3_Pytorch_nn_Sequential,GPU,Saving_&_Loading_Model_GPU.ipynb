{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZTvWiACYU9-"
   },
   "source": [
    " In this tutorial ,  we will create a Deep Learning model for building a handwritten digit classifier. We will make use of the MNIST dataset included in the torchvision package.\n",
    " \n",
    " Mandatory first step is to do the basic data pre-processing steps , using the a utility called transforms which comes from \n",
    " torchvision package we will do two below mentioned basic data preprocessing operations (this will be explained more detail in case of CNN).\n",
    " \n",
    "- Transform the raw dataset into tensors.\n",
    "- Normalize the dataset.\n",
    "\n",
    "We will also import the dataset from torch vision package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5CLuiZp8YU-A"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYdFcUzYYU-E"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7T_b51_NYU-G"
   },
   "source": [
    "For the sake of simplicity we are only using the training dataset in this tutorial\n",
    "\n",
    "Test and Validation dataset have been used in the previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "V3bcYm8oYU-G",
    "outputId": "9f220b8f-5354-4844-d119-a8eaf7cadd61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# choose the training dataset\n",
    "train_data = MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3fX_9qmKYU-J",
    "outputId": "bb5ead2e-dda4-40a6-8986-b90f60e2b41c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of train dataset\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5b8hSRs_YU-N"
   },
   "outputs": [],
   "source": [
    "# how many samples per batch to load\n",
    "batch_size = 50\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9W0n3OXYU-Q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# data loader preparation\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3usqK6eyYU-X"
   },
   "source": [
    "DataLoader creates iterables for all the batches and we will use this inside the traning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ev35zm85YU-Y",
    "outputId": "4906475e-5685-426d-a17b-5766e100e026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Let's check the shape of the input/target data\n",
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYk4Sm0KYU-c"
   },
   "source": [
    "## nn.Sequential:\n",
    "\n",
    "Below we have defined the Deep Neural Network archietecture with the help of nn.Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ot7zZpZYU-d"
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.3),\n",
    "                      nn.Linear(512, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.3),\n",
    "                      nn.Linear(128, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeaRuyujYU-g"
   },
   "outputs": [],
   "source": [
    "# Loss Function and Optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnoJSt9-YU-j"
   },
   "source": [
    "## GPU Support:\n",
    "First check that your GPU is working in Pytorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-Yt_HB5CYU-k",
    "outputId": "77e1db65-3425-4131-aac4-074fae49df73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4lH4K_VLYU-o",
    "outputId": "97e7cf41-2af9-4a39-8ed9-f7a77f59cc4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Creating a device object \n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I1GGqnaLYU-r"
   },
   "outputs": [],
   "source": [
    "# Taking the model to avialable 'device'\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlkuIIhxYU-u"
   },
   "source": [
    "<b>Traning the Model:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "pyr2SBCDYU-v",
    "outputId": "a96fc63d-f776-4010-df17-c549f72b880d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss:  0.9497286022019883\n",
      "Epoch: 2 Training Loss:  0.41989012237327794\n",
      "Epoch: 3 Training Loss:  0.3387773885391653\n",
      "Epoch: 4 Training Loss:  0.29378463465875637\n",
      "Epoch: 5 Training Loss:  0.25981339811968307\n",
      "Epoch: 6 Training Loss:  0.23041640498675406\n",
      "Epoch: 7 Training Loss:  0.20973534538721045\n",
      "Epoch: 8 Training Loss:  0.19030428069954117\n",
      "Epoch: 9 Training Loss:  0.17700108188126856\n",
      "Epoch: 10 Training Loss:  0.16445445171402145\n",
      "Epoch: 11 Training Loss:  0.15412131029025963\n",
      "Epoch: 12 Training Loss:  0.1436874617403373\n",
      "Epoch: 13 Training Loss:  0.1364887386901925\n",
      "Epoch: 14 Training Loss:  0.128194265194082\n",
      "Epoch: 15 Training Loss:  0.1206555999823225\n",
      "CPU times: user 2min 34s, sys: 4.73 s, total: 2min 39s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 16): ## run the model for 15 epochs\n",
    "    train_loss = []\n",
    "    ## training part \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        \n",
    "        # Move input and label tensors to the avialable device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        #Reshaping the input data before sending into the model\n",
    "        data = data.view(data.shape[0], -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ## 1. forward propagation\n",
    "        output = model(data)\n",
    "        \n",
    "        ## 2. loss calculation\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        ## 3. backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 4. weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Gx-DbRWYU-0"
   },
   "source": [
    "## Save & Load The Model:\n",
    "As now the model has been trained , we will save the model and load again for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "S1okLKUOYU-0",
    "outputId": "bf14e4a2-d387-4a6a-8fc5-f87a05e2345f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing our model: \n",
      "\n",
      " Sequential(\n",
      "  (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Dropout(p=0.3)\n",
      "  (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "  (4): ReLU()\n",
      "  (5): Dropout(p=0.3)\n",
      "  (6): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"printing our model: \\n\\n\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NolV8sdUYU-6"
   },
   "source": [
    "To see the weights and biases of the model \n",
    "\n",
    "The parameters for PyTorch models are stored in a model's state_dict. state_dict containts the weights & biases of each of the layer , which can be accesed by <b>state_dict().keys()</b>. \n",
    "\n",
    "Below we can see that , every layer's weight and biases have been printed out -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "CZZsd9G9YU-8",
    "outputId": "e3e6a464-6bb3-4b5c-aca2-3e7542cb4426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models layer keys: \n",
      "\n",
      " odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Models layer keys: \\n\\n\", model.state_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXnolobsYU_E"
   },
   "source": [
    "Model's statedict can be saved using the torch.save which also accepts the models name as parameter as - <b>model.pth</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31a3F8bKYU_E"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isOmwH0IYU_H"
   },
   "source": [
    "Saved model can also be loaded using the <b>torch.load()</b> using the saved model's path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Kps832nvYU_H",
    "outputId": "cc0eb768-0c32-4894-a2b7-2a1f51c0afaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['0.weight', '0.bias', '3.weight', '3.bias', '6.weight', '6.bias'])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('model.pth')\n",
    "print(state_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCYH010hYU_L"
   },
   "source": [
    "To load the state dict in to the new model, you do <b>model.load_state_dict(state_dict)</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zH8bHICYU_M"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1bWQg16XYU_P"
   },
   "source": [
    "<b>Please Note:</b> Loading the state dict will work only if the new model architecture is exactly the same as the saved's model's architecture"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "1.3_Pytorch_nn.Sequential,GPU,Saving & Loading Model_GPU.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
