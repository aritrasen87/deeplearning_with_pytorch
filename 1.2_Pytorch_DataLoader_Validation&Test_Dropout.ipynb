{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this tutorial ,  we will create a Deep Learning model for building a handwritten digit classifier. We will make use of the MNIST dataset included in the torchvision package.\n",
    " \n",
    " Mandatory first step is to do the basic data pre-processing steps , using the a utility called transforms which comes from \n",
    " torchvision package we will do two below mentioned basic data preprocessing operations (this will be explained more detail in case of CNN).\n",
    " \n",
    "- Transform the raw dataset into tensors.\n",
    "- Normalize the dataset.\n",
    "\n",
    "We will also import the dataset from torch vision package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation & Test Dataset:\n",
    "When creating a machine learning model, the ultimate goal is for it to be accurate on new data, not just the data you are using to build it. The Idea of Validation set is to see if there is any overfitting going on or not. \n",
    "\n",
    "As this blog post by fast.ai says (https://www.fast.ai/2017/11/13/validation-sets/) about the different datasets:\n",
    "\n",
    "- The training set is used to train a given model\n",
    "- The validation set is used to choose between models (for instance, does a random forest or a neural net work better for your problem? do you want a random forest with 40 trees or 50 trees?)\n",
    "- The test set tells you how you’ve done. If you’ve tried out a lot of different models, you may get one that does well on your validation set just by chance, and having a test set helps make sure that is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the training and test datasets\n",
    "train_data = MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of train and test data\n",
    "len(train_data) , len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaders:\n",
    "\n",
    "Few Terminology to understand first:\n",
    "\n",
    "When the no of tranining examples are very big , then we don't pass the dataset for traninig , we create batches first and then do one forward pass + one backward pass.\n",
    "\n",
    "- <b>epoch</b>: one forward pass + one backward pass of all traning example\n",
    "- <b>batch size</b>: number of traning examples in one epoch.\n",
    "- <b>Iterations</b>: if you have 1000 no of traning examples(or rows) and your batch size is 100 then you will need 10 iterations to complete one epoch.\n",
    "\n",
    "Pytorch's DataLoader is responsible for managing & creating batches. DataLoader makes it easier to iterate over batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples per batch to load\n",
    "batch_size = 50\n",
    "# percentage of training set to use as validation\n",
    "valid_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Here we will use a subset of traning set for validation\n",
    "# obtain training indices that will be used for validation\n",
    "num_train = len(train_data)\n",
    "ix = list(range(num_train))\n",
    "np.random.shuffle(ix)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = ix[split:], ix[:split]\n",
    "\n",
    "# create sampler objects using SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "# data loaders preparation\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "valid_loader = DataLoader(train_data, batch_size=batch_size, \n",
    "    sampler=valid_sampler)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader creates iterables for all the batches and we will use this inside the traning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 28, 28])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "# Let's check the shape of the input/target data\n",
    "for data, target in train_loader:\n",
    "    print(data.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout:\n",
    "A simple but effective regularization technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass and any weight updates are not applied to the neuron on the backward pass. Dropout is again used to reduce the '<b>overfitting problem</b>'. Drop is more useful when we have deep network. We give a dropout probablity(to switch off the weights randomly) in the configuration. \n",
    "\n",
    "Dropout is generally used during the training phase only and we switch off dropout during test/validation phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 56)\n",
    "        self.fc5 = nn.Linear(56, 10)\n",
    "        \n",
    "        #drop out with 0.3 probability\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input tensor is flattened \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        # applied dropout layer\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.dropout(F.relu(self.fc4(x)))\n",
    "        \n",
    "        #no dropout at the output layer\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "from torch import optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Traning the Model:<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss:  2.1871625877916814 Valid Loss:  1.667852665980657\n",
      "Epoch: 2 Training Loss:  1.1969949032490452 Valid Loss:  0.6726877966274818\n",
      "Epoch: 3 Training Loss:  0.7181357967667281 Valid Loss:  0.4598126212755839\n",
      "Epoch: 4 Training Loss:  0.5422619129065425 Valid Loss:  0.34589868066832424\n",
      "Epoch: 5 Training Loss:  0.4389304482378066 Valid Loss:  0.3017367086062829\n",
      "Epoch: 6 Training Loss:  0.3676402278554936 Valid Loss:  0.24089869467231134\n",
      "Epoch: 7 Training Loss:  0.3171034183508406 Valid Loss:  0.20431646563423175\n",
      "Epoch: 8 Training Loss:  0.27840177100539826 Valid Loss:  0.18733948226242017\n",
      "Epoch: 9 Training Loss:  0.2446655814012047 Valid Loss:  0.17578503578746071\n",
      "Epoch: 10 Training Loss:  0.22932315228584532 Valid Loss:  0.17078397002769635\n",
      "Epoch: 11 Training Loss:  0.20719245270205042 Valid Loss:  0.15078213748444494\n",
      "Epoch: 12 Training Loss:  0.19494042920608384 Valid Loss:  0.14527840617811308\n",
      "Epoch: 13 Training Loss:  0.17940984132001175 Valid Loss:  0.13547859613706048\n",
      "Epoch: 14 Training Loss:  0.1698654041256911 Valid Loss:  0.13429346470705544\n",
      "Epoch: 15 Training Loss:  0.1542395045806188 Valid Loss:  0.13282576212271427\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 16): ## run the model for 15 epochs\n",
    "    train_loss, valid_loss = [], []\n",
    "    ## training part \n",
    "    model.train()\n",
    "    for data, target in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        ## 1. forward propagation\n",
    "        output = model(data)\n",
    "        \n",
    "        ## 2. loss calculation\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        ## 3. backward propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        ## 4. weight optimization\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    ## evaluation part\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for data, target in valid_loader:\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss.append(loss.item())\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Few Steps to note:\n",
    "\n",
    "- <b>torch.no_grad()</b>: impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop. We generally don't want backpropagation in validation and test phase.\n",
    "- <b>model.eval()</b>: This will switch off the dropouts for validation phase. \n",
    "- <b>model.train()</b>: Will bring the model again into traning phase by switching on the dropouts.\n",
    "\n",
    "If the loss of traning set and validation set are very close that means there is lesser overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the network\n",
    "See the performence on the test dataset and also check the classwise accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.117385\n",
      "\n",
      "Test Accuracy of     0: 98% (966/980)\n",
      "Test Accuracy of     1: 99% (1124/1135)\n",
      "Test Accuracy of     2: 96% (999/1032)\n",
      "Test Accuracy of     3: 95% (963/1010)\n",
      "Test Accuracy of     4: 95% (933/982)\n",
      "Test Accuracy of     5: 94% (846/892)\n",
      "Test Accuracy of     6: 97% (938/958)\n",
      "Test Accuracy of     7: 95% (981/1028)\n",
      "Test Accuracy of     8: 95% (929/974)\n",
      "Test Accuracy of     9: 95% (963/1009)\n",
      "\n",
      "Test Accuracy (Overall): 96% (9642/10000)\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval() # prep model for evaluation\n",
    "\n",
    "for data, target in test_loader:\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = model(data)\n",
    "    # calculate the loss\n",
    "    loss = criterion(output, target)\n",
    "    # update test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    #test_loss.append(loss.item())\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)\n",
    "    # compare predictions to true label\n",
    "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(batch_size):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            str(i), 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "    else:\n",
    "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
    "\n",
    "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
    "    100. * np.sum(class_correct) / np.sum(class_total),\n",
    "    np.sum(class_correct), np.sum(class_total)))\n",
    "\n",
    "# Code Credit : Udacity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
